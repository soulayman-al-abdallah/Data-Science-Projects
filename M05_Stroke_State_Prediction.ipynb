{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M05-Stroke State Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "d1GOfAgt4M-Q",
        "KICuY0lg5nUD",
        "AD57fE2n7QP4",
        "U5zevRH57X8v",
        "IImSYWQGBSz6",
        "ngJVLbRKG7U_",
        "mXf6cpO_KWTs"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soulayman-al-abdallah/Data-Science-Projects/blob/main/M05_Stroke_State_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g2RQRSltgja"
      },
      "source": [
        "\n",
        "**Objective:** We will apply use deep learning to develop a solution that predicts if a person will have a stroke or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSCD88NxJjFo"
      },
      "source": [
        "**Dataset Explanation:** We will be using the stroke dataset. Its features are:\n",
        "\n",
        "\n",
        "* **id:** unique identifier\n",
        "* **gender:** \"Male\", \"Female\" or \"Other\"\n",
        "* **age:** age of the patient\n",
        "* **hypertension:** 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
        "* **heart_disease:** 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
        "* **ever_married:** \"No\" or \"Yes\"\n",
        "* **work_type:** \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
        "* **Residence_type:** \"Rural\" or \"Urban\"\n",
        "* **avg_glucose_level:** average glucose level in blood\n",
        "* **bmi:** body mass index\n",
        "* **smoking_status:** \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
        "* **stroke:** 1 if the patient had a stroke or 0 if not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBvX5nCYt8cT"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMQuUG7OtfrG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-RxAH5auFFy"
      },
      "source": [
        "#Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UQVo1CAJt7s8",
        "outputId": "4a6c833a-6b77-462c-c0db-acb0ff096872"
      },
      "source": [
        "path = '/content/healthcare-dataset-stroke-data.csv'\n",
        "data = pd.read_csv(path)\n",
        "data.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
              "0   9046    Male  67.0             0              1          Yes   \n",
              "1  51676  Female  61.0             0              0          Yes   \n",
              "2  31112    Male  80.0             0              1          Yes   \n",
              "3  60182  Female  49.0             0              0          Yes   \n",
              "4   1665  Female  79.0             1              0          Yes   \n",
              "\n",
              "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
              "0        Private          Urban             228.69  36.6  formerly smoked   \n",
              "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
              "2        Private          Rural             105.92  32.5     never smoked   \n",
              "3        Private          Urban             171.23  34.4           smokes   \n",
              "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
              "\n",
              "   stroke  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55e9642d-9b54-4a1b-a34a-ad1a06b79951\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55e9642d-9b54-4a1b-a34a-ad1a06b79951')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55e9642d-9b54-4a1b-a34a-ad1a06b79951 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55e9642d-9b54-4a1b-a34a-ad1a06b79951');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6gAyBGtubI7"
      },
      "source": [
        "#Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2925yVCdud0a"
      },
      "source": [
        "###Shape of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pvWR3PKuQEy",
        "outputId": "26176d2b-1c26-47df-a20a-d9952acda56a"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5110, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUy4oI5xukRr"
      },
      "source": [
        "###Types of different Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8snoohouhUP",
        "outputId": "de9375cb-c600-49f7-de4d-66bfdc789605"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5110 entries, 0 to 5109\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 5110 non-null   int64  \n",
            " 1   gender             5110 non-null   object \n",
            " 2   age                5110 non-null   float64\n",
            " 3   hypertension       5110 non-null   int64  \n",
            " 4   heart_disease      5110 non-null   int64  \n",
            " 5   ever_married       5110 non-null   object \n",
            " 6   work_type          5110 non-null   object \n",
            " 7   Residence_type     5110 non-null   object \n",
            " 8   avg_glucose_level  5110 non-null   float64\n",
            " 9   bmi                4909 non-null   float64\n",
            " 10  smoking_status     5110 non-null   object \n",
            " 11  stroke             5110 non-null   int64  \n",
            "dtypes: float64(3), int64(4), object(5)\n",
            "memory usage: 479.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkrEh6RYygms"
      },
      "source": [
        "###Dealing with categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlSfSQ35ykgc",
        "outputId": "e8649e85-059b-464f-c687-bfd7a3634b3f"
      },
      "source": [
        "data['smoking_status'].value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "never smoked       1892\n",
              "Unknown            1544\n",
              "formerly smoked     885\n",
              "smokes              789\n",
              "Name: smoking_status, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg0xlLNUy7AF",
        "outputId": "ca18b65d-cf20-4ca0-f7db-4782e19c913a"
      },
      "source": [
        "data['Residence_type'].value_counts()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Urban    2596\n",
              "Rural    2514\n",
              "Name: Residence_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T72r_mkrzF9V",
        "outputId": "2a8cdb65-c1c6-42a8-c9b8-6f94409fa1e6"
      },
      "source": [
        "data['work_type'].value_counts()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Private          2925\n",
              "Self-employed     819\n",
              "children          687\n",
              "Govt_job          657\n",
              "Never_worked       22\n",
              "Name: work_type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0kpR57LzQE9",
        "outputId": "6cd88482-be21-4392-f1e2-71f75571925b"
      },
      "source": [
        "data['ever_married'].value_counts()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yes    3353\n",
              "No     1757\n",
              "Name: ever_married, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQIoAs8y3igG",
        "outputId": "f0ab4125-206f-4fc1-8421-f21f37d278b2"
      },
      "source": [
        "data['hypertension'].value_counts()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4612\n",
              "1     498\n",
              "Name: hypertension, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEhNH46j3p3Y",
        "outputId": "08fa40e9-e5af-4c58-d890-cf4be43bfc2c"
      },
      "source": [
        "data['heart_disease'].value_counts()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4834\n",
              "1     276\n",
              "Name: heart_disease, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cI7uJvA3Njv",
        "outputId": "ff0fdf01-19c1-43a2-b910-5581ca87323b"
      },
      "source": [
        "data ['stroke'].value_counts()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4861\n",
              "1     249\n",
              "Name: stroke, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jFIiKPvllld"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsQQj-wVlkjS"
      },
      "source": [
        "###Dealing with Nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UDrnGK6lYiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02df5b1a-7c45-4768-d8c8-405ed4446667"
      },
      "source": [
        "# fill the nulls of bmi column with the mean value\n",
        "data['bmi'].fillna(value=data['bmi'].mean(), inplace=True)\n",
        "data.isnull().sum()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                   0\n",
              "gender               0\n",
              "age                  0\n",
              "hypertension         0\n",
              "heart_disease        0\n",
              "ever_married         0\n",
              "work_type            0\n",
              "Residence_type       0\n",
              "avg_glucose_level    0\n",
              "bmi                  0\n",
              "smoking_status       0\n",
              "stroke               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21da4C_Bzd-u"
      },
      "source": [
        "####Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaNk4gWCLqe4"
      },
      "source": [
        "Here we will encode those categorical variables to be able to use them to train our DL model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJtOvxdzi_G"
      },
      "source": [
        "# encode those categorical variables to be able to use them to train our DL model\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "data['smoking_status'] = encoder.fit_transform(data['smoking_status'])\n",
        "data['Residence_type'] = encoder.fit_transform(data['Residence_type'])\n",
        "data['work_type'] = encoder.fit_transform(data['work_type'])\n",
        "data['ever_married'] = encoder.fit_transform(data['ever_married'])\n",
        "data['gender'] = encoder.fit_transform(data['gender'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1GOfAgt4M-Q"
      },
      "source": [
        "###Normalizing Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPpkMCXELwty"
      },
      "source": [
        "Now we normalize the input data by dividing with the max value of each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BtI_XA-m33Bx",
        "outputId": "b4154e88-20dd-40ac-b58c-a2b920703691"
      },
      "source": [
        "data = data.divide(data.max(axis=0))\n",
        "\n",
        "data.describe()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id       gender          age  hypertension  heart_disease  \\\n",
              "count  5110.000000  5110.000000  5110.000000   5110.000000    5110.000000   \n",
              "mean      0.500656     0.207143     0.527154      0.097456       0.054012   \n",
              "std       0.290125     0.246522     0.275764      0.296607       0.226063   \n",
              "min       0.000919     0.000000     0.000976      0.000000       0.000000   \n",
              "25%       0.243231     0.000000     0.304878      0.000000       0.000000   \n",
              "50%       0.506334     0.000000     0.548780      0.000000       0.000000   \n",
              "75%       0.749685     0.500000     0.743902      0.000000       0.000000   \n",
              "max       1.000000     1.000000     1.000000      1.000000       1.000000   \n",
              "\n",
              "       ever_married    work_type  Residence_type  avg_glucose_level  \\\n",
              "count   5110.000000  5110.000000     5110.000000        5110.000000   \n",
              "mean       0.656164     0.541928        0.508023           0.390622   \n",
              "std        0.475034     0.272573        0.499985           0.166643   \n",
              "min        0.000000     0.000000        0.000000           0.202841   \n",
              "25%        0.000000     0.500000        0.000000           0.284261   \n",
              "50%        1.000000     0.500000        1.000000           0.338136   \n",
              "75%        1.000000     0.750000        1.000000           0.419850   \n",
              "max        1.000000     1.000000        1.000000           1.000000   \n",
              "\n",
              "               bmi  smoking_status       stroke  \n",
              "count  5110.000000     5110.000000  5110.000000  \n",
              "mean      0.296037        0.458969     0.048728  \n",
              "std       0.078873        0.357178     0.215320  \n",
              "min       0.105533        0.000000     0.000000  \n",
              "25%       0.243852        0.000000     0.000000  \n",
              "50%       0.290984        0.666667     0.000000  \n",
              "75%       0.336066        0.666667     0.000000  \n",
              "max       1.000000        1.000000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc71faa3-65f9-47ef-9ab3-0d489b2acdb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500656</td>\n",
              "      <td>0.207143</td>\n",
              "      <td>0.527154</td>\n",
              "      <td>0.097456</td>\n",
              "      <td>0.054012</td>\n",
              "      <td>0.656164</td>\n",
              "      <td>0.541928</td>\n",
              "      <td>0.508023</td>\n",
              "      <td>0.390622</td>\n",
              "      <td>0.296037</td>\n",
              "      <td>0.458969</td>\n",
              "      <td>0.048728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.290125</td>\n",
              "      <td>0.246522</td>\n",
              "      <td>0.275764</td>\n",
              "      <td>0.296607</td>\n",
              "      <td>0.226063</td>\n",
              "      <td>0.475034</td>\n",
              "      <td>0.272573</td>\n",
              "      <td>0.499985</td>\n",
              "      <td>0.166643</td>\n",
              "      <td>0.078873</td>\n",
              "      <td>0.357178</td>\n",
              "      <td>0.215320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000919</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000976</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.202841</td>\n",
              "      <td>0.105533</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.243231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304878</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.284261</td>\n",
              "      <td>0.243852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.506334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.548780</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.338136</td>\n",
              "      <td>0.290984</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.749685</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.743902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.419850</td>\n",
              "      <td>0.336066</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc71faa3-65f9-47ef-9ab3-0d489b2acdb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc71faa3-65f9-47ef-9ab3-0d489b2acdb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc71faa3-65f9-47ef-9ab3-0d489b2acdb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICuY0lg5nUD"
      },
      "source": [
        "###Removing Unnecessary Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AHNqYbh5sE7"
      },
      "source": [
        "# we can remove the ID feature because it's irrelevant to our predictions\n",
        "data = data.drop('id', axis=1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k-KoLpH5C9R"
      },
      "source": [
        "#Building the DL Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZvKqqT65E0W",
        "outputId": "0536631b-abdb-4ff4-e98b-3e135f8ae844"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, input_dim=10, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 32)                352       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,065\n",
            "Trainable params: 1,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD57fE2n7QP4"
      },
      "source": [
        "###Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woSsSTEm61_U"
      },
      "source": [
        "#compile the model & we want to measure the accuracy, precision and recall to know better about the performance of our model.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5zevRH57X8v"
      },
      "source": [
        "###Fitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsVOVfn47MLn",
        "outputId": "423fa79c-5784-44e5-ac80-465545446808"
      },
      "source": [
        "#we take the first columns as features and the last column as a label, then we split our dataset between training and testing, \n",
        "#and we fit the model on training data, and validate on the testing data. The training happens for 15 epochs.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = data.iloc[:,:-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "112/112 [==============================] - 2s 7ms/step - loss: 0.2830 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.2057 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 2/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1933 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1866 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 3/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1753 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 4/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1732 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1702 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 5/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1670 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 6/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1653 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 7/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1632 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 8/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1611 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 9/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1611 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 10/15\n",
            "112/112 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1630 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 11/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1615 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 12/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1621 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 13/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1604 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 14/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1611 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
            "Epoch 15/15\n",
            "112/112 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9514 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.1638 - val_accuracy: 0.9511 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbdb052fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sPVIoABAa8Q"
      },
      "source": [
        "**▶  We can see that:**\n",
        "\n",
        "We have a precision and a recall so close to zero, which means the model is not predicting any positive value, so we need to improve it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "JF0Y0VOpwgu5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqUo00lAqCZ"
      },
      "source": [
        "#Improving DL Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IImSYWQGBSz6"
      },
      "source": [
        "###Checking For Data Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHxCONODMkNN"
      },
      "source": [
        "We check for imbalance because we have a poor recall and precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1bF6G8c58SOE",
        "outputId": "4e71a9ef-9a47-4f87-bf20-e26caad5102b"
      },
      "source": [
        "#checking if there is an imbalance case by visualizing the stroke data using a histogram\n",
        "data['stroke'].hist()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbbddb04b90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARQElEQVR4nO3cf4xlZX3H8fdH1h8Uf4CiE7LQLo1rWpSoZIIYm3aUFhZsXJIqwWBZzaabWNrYlrTF9g9afySSBm01/tqWjatBgdra3Sgt3QAT0qaLQFEQKGVElN2iVBe3HYm2a7/94z5Lp7jD3Nl79w7j834lkznnOc855/nO7H7OueecOakqJEl9eNpKD0CSNDmGviR1xNCXpI4Y+pLUEUNfkjqyZqUH8GSOP/74Wrdu3WGv/73vfY9jjjlmfAN6iuutXrDmXljz8tx+++3frqoXHmrZUzr0161bx2233XbY68/OzjIzMzO+AT3F9VYvWHMvrHl5knx9sWVDXd5J8mCSu5J8Kcltre35SXYlub99P661J8kHk8wluTPJaQu2s6n1vz/JpsOqRpJ02JZzTf+1VfWKqppu85cCN1TVeuCGNg9wDrC+fW0BPgqDgwRwGfAq4HTgsoMHCknSZIxyI3cjsL1NbwfOW9D+yRrYDRyb5ATgbGBXVe2rqkeBXcCGEfYvSVqmYa/pF/D3SQr4eFVtBaaq6uG2/JvAVJteCzy0YN09rW2x9v8nyRYGnxCYmppidnZ2yCH+qPn5+ZHWX216qxesuRfWPD7Dhv7PVdXeJC8CdiX5l4ULq6raAWFk7YCyFWB6erpGuXnT282f3uoFa+6FNY/PUJd3qmpv+/4I8DkG1+S/1S7b0L4/0rrvBU5asPqJrW2xdknShCwZ+kmOSfKcg9PAWcBXgJ3AwSdwNgE72vRO4KL2FM8ZwP52Geh64Kwkx7UbuGe1NknShAxzeWcK+FySg/0/XVV/l+RW4Nokm4GvA+e3/tcB5wJzwGPA2wCqal+SdwO3tn7vqqp9Y6tEkrSkJUO/qh4AXn6I9u8AZx6ivYCLF9nWNmDb8ocpSRqHp/Rf5I7qrr37eeulX5j4fh983+snvk9JGoYvXJOkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZOjQT3JUkjuSfL7Nn5zkliRzSa5J8ozW/sw2P9eWr1uwjXe29vuSnD3uYiRJT245Z/rvAO5dMH858IGqejHwKLC5tW8GHm3tH2j9SHIKcAHwUmAD8JEkR402fEnScgwV+klOBF4P/EWbD/A64LOty3bgvDa9sc3Tlp/Z+m8Erq6qH1TV14A54PRxFCFJGs6aIfv9KfB7wHPa/AuA71bVgTa/B1jbptcCDwFU1YEk+1v/tcDuBdtcuM7jkmwBtgBMTU0xOzs7bC0/YupouOTUA0t3HLNRxjyK+fn5Fdv3SrHmPljz+CwZ+kl+GXikqm5PMjP2ETxBVW0FtgJMT0/XzMzh7/JDV+3giruGPa6Nz4MXzkx8nzA42Izy81qNrLkP1jw+wyTia4A3JDkXeBbwXODPgGOTrGln+ycCe1v/vcBJwJ4ka4DnAd9Z0H7QwnUkSROw5DX9qnpnVZ1YVesY3Ii9saouBG4C3ti6bQJ2tOmdbZ62/MaqqtZ+QXu652RgPfDFsVUiSVrSKNc+fh+4Osl7gDuAK1v7lcCnkswB+xgcKKiqu5NcC9wDHAAurqofjrB/SdIyLSv0q2oWmG3TD3CIp2+q6vvAmxZZ/73Ae5c7SEnSePgXuZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6smToJ3lWki8m+XKSu5P8cWs/OcktSeaSXJPkGa39mW1+ri1ft2Bb72zt9yU5+0gVJUk6tGHO9H8AvK6qXg68AtiQ5AzgcuADVfVi4FFgc+u/GXi0tX+g9SPJKcAFwEuBDcBHkhw1zmIkSU9uydCvgfk2+/T2VcDrgM+29u3AeW16Y5unLT8zSVr71VX1g6r6GjAHnD6WKiRJQ1kzTKd2Rn478GLgw8BXge9W1YHWZQ+wtk2vBR4CqKoDSfYDL2jtuxdsduE6C/e1BdgCMDU1xezs7PIqWmDqaLjk1ANLdxyzUcY8ivn5+RXb90qx5j5Y8/gMFfpV9UPgFUmOBT4H/MzYR/J/+9oKbAWYnp6umZmZw97Wh67awRV3DVXiWD144czE9wmDg80oP6/VyJr7YM3js6ynd6rqu8BNwKuBY5McTNQTgb1tei9wEkBb/jzgOwvbD7GOJGkChnl654XtDJ8kRwO/BNzLIPzf2LptAna06Z1tnrb8xqqq1n5Be7rnZGA98MVxFSJJWtow1z5OALa36/pPA66tqs8nuQe4Osl7gDuAK1v/K4FPJZkD9jF4YoequjvJtcA9wAHg4nbZSJI0IUuGflXdCbzyEO0PcIinb6rq+8CbFtnWe4H3Ln+YkqRx8C9yJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI0uGfpKTktyU5J4kdyd5R2t/fpJdSe5v349r7UnywSRzSe5MctqCbW1q/e9PsunIlSVJOpRhzvQPAJdU1SnAGcDFSU4BLgVuqKr1wA1tHuAcYH372gJ8FAYHCeAy4FXA6cBlBw8UkqTJWDL0q+rhqvrnNv2fwL3AWmAjsL112w6c16Y3Ap+sgd3AsUlOAM4GdlXVvqp6FNgFbBhrNZKkJ7Wsa/pJ1gGvBG4Bpqrq4bbom8BUm14LPLRgtT2tbbF2SdKErBm2Y5JnA38F/FZV/UeSx5dVVSWpcQwoyRYGl4WYmppidnb2sLc1dTRccuqBcQxrWUYZ8yjm5+dXbN8rxZr7YM3jM1ToJ3k6g8C/qqr+ujV/K8kJVfVwu3zzSGvfC5y0YPUTW9teYOYJ7bNP3FdVbQW2AkxPT9fMzMwTuwztQ1ft4Iq7hj6ujc2DF85MfJ8wONiM8vNajay5D9Y8PsM8vRPgSuDeqnr/gkU7gYNP4GwCdixov6g9xXMGsL9dBroeOCvJce0G7lmtTZI0IcOcBr8G+FXgriRfam1/ALwPuDbJZuDrwPlt2XXAucAc8BjwNoCq2pfk3cCtrd+7qmrfWKqQJA1lydCvqn8AssjiMw/Rv4CLF9nWNmDbcgYoSRof/yJXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkeWDP0k25I8kuQrC9qen2RXkvvb9+Nae5J8MMlckjuTnLZgnU2t//1JNh2ZciRJT2aYM/1PABue0HYpcENVrQduaPMA5wDr29cW4KMwOEgAlwGvAk4HLjt4oJAkTc6SoV9VNwP7ntC8EdjeprcD5y1o/2QN7AaOTXICcDawq6r2VdWjwC5+9EAiSTrC1hzmelNV9XCb/iYw1abXAg8t6LentS3W/iOSbGHwKYGpqSlmZ2cPc4gwdTRccuqBw17/cI0y5lHMz8+v2L5XijX3wZrH53BD/3FVVUlqHINp29sKbAWYnp6umZmZw97Wh67awRV3jVzisj144czE9wmDg80oP6/VyJr7YM3jc7hP73yrXbahfX+kte8FTlrQ78TWtli7JGmCDjf0dwIHn8DZBOxY0H5Re4rnDGB/uwx0PXBWkuPaDdyzWpskaYKWvPaR5DPADHB8kj0MnsJ5H3Btks3A14HzW/frgHOBOeAx4G0AVbUvybuBW1u/d1XVE28OS5KOsCVDv6revMiiMw/Rt4CLF9nONmDbskYnSRor/yJXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR9as9AAk6alq3aVfWLF9f2LDMUdku57pS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkYmHfpINSe5LMpfk0knvX5J6NtHQT3IU8GHgHOAU4M1JTpnkGCSpZ5M+0z8dmKuqB6rqv4CrgY0THoMkdWvSr2FYCzy0YH4P8KqFHZJsAba02fkk942wv+OBb4+w/mHJ5ZPe4+NWpN4VZs196K7m114+Us0/tdiCp9y7d6pqK7B1HNtKcltVTY9jW6tBb/WCNffCmsdn0pd39gInLZg/sbVJkiZg0qF/K7A+yclJngFcAOyc8BgkqVsTvbxTVQeS/AZwPXAUsK2q7j6CuxzLZaJVpLd6wZp7Yc1jkqo6EtuVJD0F+Re5ktQRQ1+SOrLqQ3+p1zokeWaSa9ryW5Ksm/wox2uImn8nyT1J7kxyQ5JFn9ldLYZ9fUeSX0lSSVb9433D1Jzk/Pa7vjvJpyc9xnEb4t/2Tya5Kckd7d/3uSsxznFJsi3JI0m+ssjyJPlg+3ncmeS0kXdaVav2i8HN4K8CPw08A/gycMoT+vw68LE2fQFwzUqPewI1vxb4iTb99h5qbv2eA9wM7AamV3rcE/g9rwfuAI5r8y9a6XFPoOatwNvb9CnAgys97hFr/nngNOAriyw/F/hbIMAZwC2j7nO1n+kP81qHjcD2Nv1Z4MwkmeAYx23Jmqvqpqp6rM3uZvD3EKvZsK/veDdwOfD9SQ7uCBmm5l8DPlxVjwJU1SMTHuO4DVNzAc9t088D/m2C4xu7qroZ2PckXTYCn6yB3cCxSU4YZZ+rPfQP9VqHtYv1qaoDwH7gBRMZ3ZExTM0LbWZwprCaLVlz+9h7UlV9YZIDO4KG+T2/BHhJkn9MsjvJhomN7sgYpuY/At6SZA9wHfCbkxnailnu//clPeVew6DxSfIWYBr4hZUey5GU5GnA+4G3rvBQJm0Ng0s8Mww+zd2c5NSq+u6KjurIejPwiaq6IsmrgU8leVlV/c9KD2y1WO1n+sO81uHxPknWMPhI+J2JjO7IGOpVFkl+EfhD4A1V9YMJje1IWarm5wAvA2aTPMjg2ufOVX4zd5jf8x5gZ1X9d1V9DfhXBgeB1WqYmjcD1wJU1T8Bz2LwMrYfV2N/dc1qD/1hXuuwE9jUpt8I3FjtDskqtWTNSV4JfJxB4K/267ywRM1Vtb+qjq+qdVW1jsF9jDdU1W0rM9yxGObf9t8wOMsnyfEMLvc8MMlBjtkwNX8DOBMgyc8yCP1/n+goJ2sncFF7iucMYH9VPTzKBlf15Z1a5LUOSd4F3FZVO4ErGXwEnGNww+SClRvx6Ias+U+AZwN/2e5Zf6Oq3rBigx7RkDX/WBmy5uuBs5LcA/wQ+N2qWrWfYoes+RLgz5P8NoObum9dzSdxST7D4MB9fLtPcRnwdICq+hiD+xbnAnPAY8DbRt7nKv55SZKWabVf3pEkLYOhL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjryvxN7crnVsn6mAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzZBB5GMCOld"
      },
      "source": [
        "**▶ We can say that:**\n",
        "\n",
        "We have a huge imbalance in the data, this is why we fix it with oversamppling and undersampling.\n",
        "\n",
        "We will oversample this time using the SMOTE() function instead of random oversampling, and this is because SMOTE will generate new data based on the data that we have, so we avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "US4xON4LBX8I",
        "outputId": "fc751283-0bf9-48dd-f265-c0e8227914c4"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "over = SMOTE()\n",
        "x_new, y_new = over.fit_resample(x, y)\n",
        "\n",
        "plt.hist([y_new])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4861.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
              "        4861.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6MOHwo_Ew08"
      },
      "source": [
        "Now we will fit our same model on the new data that we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26YTispLEm9N",
        "outputId": "9b243bd4-b375-41ec-f573-cb445847ef13"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size=0.3)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.5574 - accuracy: 0.7367 - precision_2: 0.7581 - recall_2: 0.6909 - val_loss: 0.5123 - val_accuracy: 0.7875 - val_precision_2: 0.7528 - val_recall_2: 0.8639\n",
            "Epoch 2/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7891 - precision_2: 0.7531 - recall_2: 0.8570 - val_loss: 0.4850 - val_accuracy: 0.7875 - val_precision_2: 0.7395 - val_recall_2: 0.8957\n",
            "Epoch 3/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.7932 - precision_2: 0.7517 - recall_2: 0.8723 - val_loss: 0.4715 - val_accuracy: 0.7960 - val_precision_2: 0.7732 - val_recall_2: 0.8450\n",
            "Epoch 4/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.7976 - precision_2: 0.7571 - recall_2: 0.8732 - val_loss: 0.4537 - val_accuracy: 0.7974 - val_precision_2: 0.7517 - val_recall_2: 0.8957\n",
            "Epoch 5/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.8028 - precision_2: 0.7576 - recall_2: 0.8874 - val_loss: 0.4498 - val_accuracy: 0.7967 - val_precision_2: 0.7859 - val_recall_2: 0.8226\n",
            "Epoch 6/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4359 - accuracy: 0.8041 - precision_2: 0.7613 - recall_2: 0.8830 - val_loss: 0.4381 - val_accuracy: 0.7933 - val_precision_2: 0.7535 - val_recall_2: 0.8795\n",
            "Epoch 7/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4293 - accuracy: 0.8032 - precision_2: 0.7610 - recall_2: 0.8809 - val_loss: 0.4339 - val_accuracy: 0.8022 - val_precision_2: 0.7548 - val_recall_2: 0.9025\n",
            "Epoch 8/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4225 - accuracy: 0.8071 - precision_2: 0.7638 - recall_2: 0.8859 - val_loss: 0.4341 - val_accuracy: 0.7929 - val_precision_2: 0.7351 - val_recall_2: 0.9242\n",
            "Epoch 9/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.8063 - precision_2: 0.7618 - recall_2: 0.8883 - val_loss: 0.4205 - val_accuracy: 0.8084 - val_precision_2: 0.7703 - val_recall_2: 0.8856\n",
            "Epoch 10/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4143 - accuracy: 0.8115 - precision_2: 0.7644 - recall_2: 0.8975 - val_loss: 0.4231 - val_accuracy: 0.7991 - val_precision_2: 0.7441 - val_recall_2: 0.9194\n",
            "Epoch 11/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4111 - accuracy: 0.8090 - precision_2: 0.7647 - recall_2: 0.8895 - val_loss: 0.4121 - val_accuracy: 0.8084 - val_precision_2: 0.7620 - val_recall_2: 0.9039\n",
            "Epoch 12/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4080 - accuracy: 0.8096 - precision_2: 0.7642 - recall_2: 0.8924 - val_loss: 0.4102 - val_accuracy: 0.8091 - val_precision_2: 0.7550 - val_recall_2: 0.9221\n",
            "Epoch 13/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4060 - accuracy: 0.8119 - precision_2: 0.7658 - recall_2: 0.8957 - val_loss: 0.4107 - val_accuracy: 0.8005 - val_precision_2: 0.7412 - val_recall_2: 0.9309\n",
            "Epoch 14/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.4006 - accuracy: 0.8137 - precision_2: 0.7683 - recall_2: 0.8954 - val_loss: 0.4020 - val_accuracy: 0.8070 - val_precision_2: 0.7594 - val_recall_2: 0.9059\n",
            "Epoch 15/15\n",
            "213/213 [==============================] - 1s 3ms/step - loss: 0.3958 - accuracy: 0.8176 - precision_2: 0.7727 - recall_2: 0.8972 - val_loss: 0.3982 - val_accuracy: 0.8087 - val_precision_2: 0.7589 - val_recall_2: 0.9120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbdac30550>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhfhpIaWGtz2"
      },
      "source": [
        "**▶ We can see that:**\n",
        "\n",
        "the performance gets better when our data became balanced.\n",
        "Now we will try improving our model with other techniques like model hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "35YmPRLv0VWM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngJVLbRKG7U_"
      },
      "source": [
        "###Model Design Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMdcXspCHxIo"
      },
      "source": [
        "We will use batch normalization after each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK78-g-hHrmq",
        "outputId": "1e2394b6-087c-4095-ed86-30a383fbcd71"
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, input_dim=10, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 32)                352       \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 16)               64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8)                32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4)                16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2)                8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,313\n",
            "Trainable params: 1,189\n",
            "Non-trainable params: 124\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3uBII4wJPbk"
      },
      "source": [
        "Let's train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REDrQVWLJLs5",
        "outputId": "e0be8584-0f49-47b8-ed8e-29bdebbebe6f"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "213/213 [==============================] - 4s 6ms/step - loss: 0.4114 - accuracy: 0.8028 - precision_5: 0.7545 - recall_5: 0.8945 - val_loss: 0.3953 - val_accuracy: 0.8094 - val_precision_5: 0.7529 - val_recall_5: 0.9282\n",
            "Epoch 2/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4153 - accuracy: 0.8004 - precision_5: 0.7608 - recall_5: 0.8732 - val_loss: 0.4018 - val_accuracy: 0.8008 - val_precision_5: 0.7314 - val_recall_5: 0.9587\n",
            "Epoch 3/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4076 - accuracy: 0.8087 - precision_5: 0.7638 - recall_5: 0.8907 - val_loss: 0.3850 - val_accuracy: 0.8121 - val_precision_5: 0.7556 - val_recall_5: 0.9296\n",
            "Epoch 4/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4062 - accuracy: 0.8025 - precision_5: 0.7613 - recall_5: 0.8783 - val_loss: 0.3871 - val_accuracy: 0.8135 - val_precision_5: 0.7545 - val_recall_5: 0.9364\n",
            "Epoch 5/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4054 - accuracy: 0.8032 - precision_5: 0.7591 - recall_5: 0.8853 - val_loss: 0.3841 - val_accuracy: 0.8118 - val_precision_5: 0.7648 - val_recall_5: 0.9072\n",
            "Epoch 6/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4089 - accuracy: 0.8032 - precision_5: 0.7565 - recall_5: 0.8913 - val_loss: 0.3836 - val_accuracy: 0.8156 - val_precision_5: 0.7587 - val_recall_5: 0.9323\n",
            "Epoch 7/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4077 - accuracy: 0.7991 - precision_5: 0.7555 - recall_5: 0.8812 - val_loss: 0.3783 - val_accuracy: 0.8193 - val_precision_5: 0.7651 - val_recall_5: 0.9282\n",
            "Epoch 8/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4029 - accuracy: 0.8016 - precision_5: 0.7664 - recall_5: 0.8647 - val_loss: 0.3901 - val_accuracy: 0.8159 - val_precision_5: 0.7704 - val_recall_5: 0.9066\n",
            "Epoch 9/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3960 - accuracy: 0.8165 - precision_5: 0.7778 - recall_5: 0.8833 - val_loss: 0.3774 - val_accuracy: 0.8279 - val_precision_5: 0.8168 - val_recall_5: 0.8510\n",
            "Epoch 10/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4020 - accuracy: 0.8024 - precision_5: 0.7734 - recall_5: 0.8522 - val_loss: 0.3717 - val_accuracy: 0.8296 - val_precision_5: 0.7719 - val_recall_5: 0.9418\n",
            "Epoch 11/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8112 - precision_5: 0.7750 - recall_5: 0.8741 - val_loss: 0.3721 - val_accuracy: 0.8197 - val_precision_5: 0.7970 - val_recall_5: 0.8639\n",
            "Epoch 12/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3913 - accuracy: 0.8154 - precision_5: 0.7812 - recall_5: 0.8735 - val_loss: 0.3772 - val_accuracy: 0.8159 - val_precision_5: 0.7538 - val_recall_5: 0.9452\n",
            "Epoch 13/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3947 - accuracy: 0.8094 - precision_5: 0.7735 - recall_5: 0.8720 - val_loss: 0.3842 - val_accuracy: 0.8156 - val_precision_5: 0.7457 - val_recall_5: 0.9648\n",
            "Epoch 14/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8069 - precision_5: 0.7751 - recall_5: 0.8617 - val_loss: 0.3698 - val_accuracy: 0.8221 - val_precision_5: 0.7682 - val_recall_5: 0.9289\n",
            "Epoch 15/15\n",
            "213/213 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8107 - precision_5: 0.7714 - recall_5: 0.8803 - val_loss: 0.3693 - val_accuracy: 0.8258 - val_precision_5: 0.7751 - val_recall_5: 0.9242\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbd7e822d0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhkSEThVKEdm"
      },
      "source": [
        "We see that we are achieving better metrics (more significant in the validation metrics) with batch normalization. 👍"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MEkubvtd11nV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXf6cpO_KWTs"
      },
      "source": [
        "###Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2rMJJEcNDil"
      },
      "source": [
        "Now we will tune some hyperparameters of our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQl4VxrOLQGO"
      },
      "source": [
        "We start by wrapping our keras model inside a kerasClassifier to be able to use it in Scikit Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYBO5H5LLW4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af4270c-faf3-4bff-bb9c-ebc870f6e679"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#create a fn that create the model when called\n",
        "def create_model():\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(32, input_dim=10, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(4, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(2, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "  return model \n",
        "\n",
        "#create an instance of the wrapper and pass it the fn as an argument\n",
        "model_wrapper = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIqMITAEKoue"
      },
      "source": [
        "We will tune the batch size and the number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_XXldXwJ-Ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516e20b8-2d86-425d-8d82-14335f31ed1e"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#pass the instance (model_wrapper) to the tuning tool by sklearn call gridsearchCV,     rather than passing the model itself.\n",
        "params = {'batch_size': [50, 100],\n",
        "          'epochs': [50, 100]}\n",
        "\n",
        "grid = GridSearchCV(estimator=model_wrapper, param_grid=params, cv=3, verbose=3)\n",
        "grid_result = grid.fit(x_train, y_train)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 2s 3ms/step - loss: 0.6244 - accuracy: 0.6680 - precision_6: 0.6614 - recall_6: 0.6702\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7346 - precision_6: 0.7161 - recall_6: 0.7654\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7612 - precision_6: 0.7349 - recall_6: 0.8074\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7773 - precision_6: 0.7446 - recall_6: 0.8351\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7890 - precision_6: 0.7485 - recall_6: 0.8619\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7892 - precision_6: 0.7483 - recall_6: 0.8633\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7967 - precision_6: 0.7578 - recall_6: 0.8642\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7948 - precision_6: 0.7532 - recall_6: 0.8686\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8003 - precision_6: 0.7534 - recall_6: 0.8847\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8064 - precision_6: 0.7603 - recall_6: 0.8874\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8102 - precision_6: 0.7657 - recall_6: 0.8865\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8056 - precision_6: 0.7610 - recall_6: 0.8834\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8128 - precision_6: 0.7670 - recall_6: 0.8914\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8172 - precision_6: 0.7736 - recall_6: 0.8901\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8179 - precision_6: 0.7745 - recall_6: 0.8901\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8148 - precision_6: 0.7756 - recall_6: 0.8789\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8177 - precision_6: 0.7727 - recall_6: 0.8932\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8219 - precision_6: 0.7842 - recall_6: 0.8816\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8302 - precision_6: 0.7819 - recall_6: 0.9097\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8287 - precision_6: 0.7855 - recall_6: 0.8981\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8243 - precision_6: 0.7874 - recall_6: 0.8820\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8243 - precision_6: 0.7809 - recall_6: 0.8950\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8325 - precision_6: 0.7875 - recall_6: 0.9044\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8331 - precision_6: 0.7926 - recall_6: 0.8963\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8353 - precision_6: 0.7884 - recall_6: 0.9106\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8300 - precision_6: 0.7893 - recall_6: 0.8941\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8318 - precision_6: 0.7891 - recall_6: 0.8995\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8364 - precision_6: 0.7947 - recall_6: 0.9013\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8384 - precision_6: 0.8018 - recall_6: 0.8932\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8338 - precision_6: 0.7924 - recall_6: 0.8986\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8446 - precision_6: 0.8082 - recall_6: 0.8981\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8386 - precision_6: 0.7944 - recall_6: 0.9080\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8384 - precision_6: 0.7975 - recall_6: 0.9013\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8466 - precision_6: 0.8014 - recall_6: 0.9160\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8333 - precision_6: 0.7988 - recall_6: 0.8852\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8430 - precision_6: 0.7983 - recall_6: 0.9124\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8428 - precision_6: 0.7989 - recall_6: 0.9106\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8428 - precision_6: 0.8029 - recall_6: 0.9030\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8408 - precision_6: 0.7991 - recall_6: 0.9048\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8448 - precision_6: 0.8010 - recall_6: 0.9120\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8503 - precision_6: 0.8065 - recall_6: 0.9164\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8444 - precision_6: 0.8032 - recall_6: 0.9066\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8477 - precision_6: 0.8063 - recall_6: 0.9097\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8514 - precision_6: 0.8123 - recall_6: 0.9088\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8501 - precision_6: 0.8131 - recall_6: 0.9039\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8455 - precision_6: 0.8048 - recall_6: 0.9066\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8519 - precision_6: 0.8112 - recall_6: 0.9120\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8516 - precision_6: 0.8121 - recall_6: 0.9097\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8541 - precision_6: 0.8134 - recall_6: 0.9138\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8602 - precision_6: 0.8190 - recall_6: 0.9200\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8576 - precision_6: 0.8073 - recall_6: 0.9433\n",
            "[CV 1/3] END ..........batch_size=50, epochs=50;, score=0.858 total time=  23.4s\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 2s 4ms/step - loss: 0.7122 - accuracy: 0.5576 - precision_7: 0.5689 - recall_7: 0.5246\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6515 - precision_7: 0.6610 - recall_7: 0.6411\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7108 - precision_7: 0.7043 - recall_7: 0.7399\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7434 - precision_7: 0.7473 - recall_7: 0.7460\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7637 - precision_7: 0.7625 - recall_7: 0.7751\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7692 - precision_7: 0.7589 - recall_7: 0.7982\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7794 - precision_7: 0.7729 - recall_7: 0.7995\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7816 - precision_7: 0.7743 - recall_7: 0.8030\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7888 - precision_7: 0.7747 - recall_7: 0.8225\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7928 - precision_7: 0.7825 - recall_7: 0.8186\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7935 - precision_7: 0.7768 - recall_7: 0.8312\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7937 - precision_7: 0.7831 - recall_7: 0.8199\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7950 - precision_7: 0.7786 - recall_7: 0.8321\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7994 - precision_7: 0.7804 - recall_7: 0.8408\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8153 - precision_7: 0.7933 - recall_7: 0.8595\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8016 - precision_7: 0.7770 - recall_7: 0.8534\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8142 - precision_7: 0.7887 - recall_7: 0.8652\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8100 - precision_7: 0.7795 - recall_7: 0.8717\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8133 - precision_7: 0.7823 - recall_7: 0.8752\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8142 - precision_7: 0.7857 - recall_7: 0.8708\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8144 - precision_7: 0.7929 - recall_7: 0.8578\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8063 - precision_7: 0.7739 - recall_7: 0.8726\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8195 - precision_7: 0.7877 - recall_7: 0.8813\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8219 - precision_7: 0.7888 - recall_7: 0.8856\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8162 - precision_7: 0.7901 - recall_7: 0.8678\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8276 - precision_7: 0.7985 - recall_7: 0.8826\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3945 - accuracy: 0.8184 - precision_7: 0.7963 - recall_7: 0.8621\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3886 - accuracy: 0.8219 - precision_7: 0.7879 - recall_7: 0.8873\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8272 - precision_7: 0.7960 - recall_7: 0.8860\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8263 - precision_7: 0.8004 - recall_7: 0.8756\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8243 - precision_7: 0.7957 - recall_7: 0.8791\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8358 - precision_7: 0.8096 - recall_7: 0.8839\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3697 - accuracy: 0.8294 - precision_7: 0.8013 - recall_7: 0.8821\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8327 - precision_7: 0.8031 - recall_7: 0.8873\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8314 - precision_7: 0.7996 - recall_7: 0.8904\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8373 - precision_7: 0.8091 - recall_7: 0.8886\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8336 - precision_7: 0.8071 - recall_7: 0.8826\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3656 - accuracy: 0.8347 - precision_7: 0.8084 - recall_7: 0.8830\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8318 - precision_7: 0.8012 - recall_7: 0.8886\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8389 - precision_7: 0.8067 - recall_7: 0.8969\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8422 - precision_7: 0.8165 - recall_7: 0.8882\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3581 - accuracy: 0.8384 - precision_7: 0.8075 - recall_7: 0.8943\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 1s 5ms/step - loss: 0.3573 - accuracy: 0.8417 - precision_7: 0.8158 - recall_7: 0.8882\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8404 - precision_7: 0.8119 - recall_7: 0.8917\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8413 - precision_7: 0.8137 - recall_7: 0.8908\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8466 - precision_7: 0.8162 - recall_7: 0.9000\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8400 - precision_7: 0.8117 - recall_7: 0.8908\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8433 - precision_7: 0.8133 - recall_7: 0.8965\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8391 - precision_7: 0.8100 - recall_7: 0.8917\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8439 - precision_7: 0.8171 - recall_7: 0.8917\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8470 - precision_7: 0.7990 - recall_7: 0.9088\n",
            "[CV 2/3] END ..........batch_size=50, epochs=50;, score=0.847 total time=  22.3s\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 2s 3ms/step - loss: 0.5921 - accuracy: 0.6877 - precision_8: 0.6327 - recall_8: 0.8700\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7441 - precision_8: 0.6816 - recall_8: 0.9000\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7752 - precision_8: 0.7127 - recall_8: 0.9095\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7842 - precision_8: 0.7257 - recall_8: 0.9023\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7992 - precision_8: 0.7416 - recall_8: 0.9081\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7961 - precision_8: 0.7429 - recall_8: 0.8951\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7996 - precision_8: 0.7496 - recall_8: 0.8897\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8012 - precision_8: 0.7543 - recall_8: 0.8835\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8087 - precision_8: 0.7626 - recall_8: 0.8870\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8091 - precision_8: 0.7612 - recall_8: 0.8915\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8162 - precision_8: 0.7706 - recall_8: 0.8915\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8146 - precision_8: 0.7717 - recall_8: 0.8848\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8131 - precision_8: 0.7728 - recall_8: 0.8781\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8164 - precision_8: 0.7739 - recall_8: 0.8853\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8193 - precision_8: 0.7776 - recall_8: 0.8857\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8210 - precision_8: 0.7803 - recall_8: 0.8853\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8193 - precision_8: 0.7761 - recall_8: 0.8888\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8219 - precision_8: 0.7840 - recall_8: 0.8803\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8210 - precision_8: 0.7848 - recall_8: 0.8763\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8276 - precision_8: 0.7858 - recall_8: 0.8929\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8250 - precision_8: 0.7855 - recall_8: 0.8861\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8268 - precision_8: 0.7922 - recall_8: 0.8781\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8365 - precision_8: 0.7965 - recall_8: 0.8965\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8309 - precision_8: 0.7966 - recall_8: 0.8812\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8309 - precision_8: 0.7919 - recall_8: 0.8902\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8305 - precision_8: 0.7955 - recall_8: 0.8821\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8323 - precision_8: 0.7926 - recall_8: 0.8924\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8316 - precision_8: 0.7923 - recall_8: 0.8911\n",
            "Epoch 29/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8389 - precision_8: 0.7998 - recall_8: 0.8969\n",
            "Epoch 30/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8331 - precision_8: 0.7957 - recall_8: 0.8888\n",
            "Epoch 31/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8387 - precision_8: 0.7987 - recall_8: 0.8983\n",
            "Epoch 32/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8371 - precision_8: 0.7989 - recall_8: 0.8938\n",
            "Epoch 33/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8384 - precision_8: 0.8037 - recall_8: 0.8884\n",
            "Epoch 34/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8426 - precision_8: 0.8033 - recall_8: 0.9005\n",
            "Epoch 35/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8395 - precision_8: 0.8017 - recall_8: 0.8951\n",
            "Epoch 36/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8406 - precision_8: 0.8058 - recall_8: 0.8906\n",
            "Epoch 37/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8446 - precision_8: 0.8042 - recall_8: 0.9041\n",
            "Epoch 38/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8446 - precision_8: 0.8079 - recall_8: 0.8974\n",
            "Epoch 39/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8453 - precision_8: 0.8099 - recall_8: 0.8956\n",
            "Epoch 40/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8466 - precision_8: 0.8094 - recall_8: 0.9000\n",
            "Epoch 41/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8455 - precision_8: 0.8077 - recall_8: 0.9000\n",
            "Epoch 42/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8521 - precision_8: 0.8166 - recall_8: 0.9018\n",
            "Epoch 43/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8501 - precision_8: 0.8190 - recall_8: 0.8924\n",
            "Epoch 44/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8490 - precision_8: 0.8137 - recall_8: 0.8987\n",
            "Epoch 45/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8592 - precision_8: 0.8228 - recall_8: 0.9095\n",
            "Epoch 46/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8536 - precision_8: 0.8189 - recall_8: 0.9018\n",
            "Epoch 47/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8481 - precision_8: 0.8111 - recall_8: 0.9009\n",
            "Epoch 48/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8503 - precision_8: 0.8139 - recall_8: 0.9018\n",
            "Epoch 49/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8545 - precision_8: 0.8161 - recall_8: 0.9090\n",
            "Epoch 50/50\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8565 - precision_8: 0.8211 - recall_8: 0.9054\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8492 - precision_8: 0.8146 - recall_8: 0.9107\n",
            "[CV 3/3] END ..........batch_size=50, epochs=50;, score=0.849 total time=  23.2s\n",
            "Epoch 1/100\n",
            "91/91 [==============================] - 3s 3ms/step - loss: 0.6395 - accuracy: 0.6362 - precision_9: 0.6230 - recall_9: 0.6653\n",
            "Epoch 2/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7240 - precision_9: 0.7110 - recall_9: 0.7422\n",
            "Epoch 3/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7595 - precision_9: 0.7359 - recall_9: 0.7994\n",
            "Epoch 4/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7806 - precision_9: 0.7536 - recall_9: 0.8253\n",
            "Epoch 5/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7789 - precision_9: 0.7515 - recall_9: 0.8244\n",
            "Epoch 6/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7879 - precision_9: 0.7602 - recall_9: 0.8329\n",
            "Epoch 7/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7897 - precision_9: 0.7668 - recall_9: 0.8244\n",
            "Epoch 8/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7976 - precision_9: 0.7725 - recall_9: 0.8360\n",
            "Epoch 9/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8027 - precision_9: 0.7700 - recall_9: 0.8557\n",
            "Epoch 10/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8005 - precision_9: 0.7617 - recall_9: 0.8668\n",
            "Epoch 11/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8049 - precision_9: 0.7681 - recall_9: 0.8660\n",
            "Epoch 12/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8073 - precision_9: 0.7739 - recall_9: 0.8610\n",
            "Epoch 13/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8053 - precision_9: 0.7621 - recall_9: 0.8803\n",
            "Epoch 14/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8115 - precision_9: 0.7741 - recall_9: 0.8727\n",
            "Epoch 15/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8164 - precision_9: 0.7780 - recall_9: 0.8785\n",
            "Epoch 16/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8166 - precision_9: 0.7832 - recall_9: 0.8686\n",
            "Epoch 17/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8164 - precision_9: 0.7760 - recall_9: 0.8825\n",
            "Epoch 18/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8203 - precision_9: 0.7827 - recall_9: 0.8803\n",
            "Epoch 19/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8228 - precision_9: 0.7823 - recall_9: 0.8878\n",
            "Epoch 20/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8210 - precision_9: 0.7880 - recall_9: 0.8718\n",
            "Epoch 21/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8296 - precision_9: 0.7901 - recall_9: 0.8914\n",
            "Epoch 22/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8269 - precision_9: 0.7880 - recall_9: 0.8883\n",
            "Epoch 23/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8287 - precision_9: 0.7954 - recall_9: 0.8789\n",
            "Epoch 24/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8263 - precision_9: 0.7926 - recall_9: 0.8776\n",
            "Epoch 25/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8349 - precision_9: 0.7974 - recall_9: 0.8919\n",
            "Epoch 26/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8234 - precision_9: 0.7857 - recall_9: 0.8829\n",
            "Epoch 27/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8338 - precision_9: 0.7961 - recall_9: 0.8914\n",
            "Epoch 28/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8331 - precision_9: 0.7956 - recall_9: 0.8905\n",
            "Epoch 29/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8342 - precision_9: 0.8003 - recall_9: 0.8847\n",
            "Epoch 30/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8388 - precision_9: 0.8030 - recall_9: 0.8923\n",
            "Epoch 31/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8377 - precision_9: 0.8026 - recall_9: 0.8901\n",
            "Epoch 32/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8353 - precision_9: 0.7967 - recall_9: 0.8945\n",
            "Epoch 33/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8320 - precision_9: 0.7990 - recall_9: 0.8811\n",
            "Epoch 34/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8342 - precision_9: 0.7996 - recall_9: 0.8861\n",
            "Epoch 35/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8369 - precision_9: 0.8030 - recall_9: 0.8870\n",
            "Epoch 36/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8404 - precision_9: 0.8018 - recall_9: 0.8986\n",
            "Epoch 37/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8371 - precision_9: 0.8038 - recall_9: 0.8861\n",
            "Epoch 38/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8406 - precision_9: 0.8061 - recall_9: 0.8914\n",
            "Epoch 39/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8393 - precision_9: 0.8083 - recall_9: 0.8838\n",
            "Epoch 40/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3590 - accuracy: 0.8450 - precision_9: 0.8096 - recall_9: 0.8968\n",
            "Epoch 41/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8435 - precision_9: 0.8071 - recall_9: 0.8972\n",
            "Epoch 42/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8413 - precision_9: 0.8056 - recall_9: 0.8941\n",
            "Epoch 43/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8494 - precision_9: 0.8144 - recall_9: 0.8999\n",
            "Epoch 44/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8386 - precision_9: 0.8084 - recall_9: 0.8820\n",
            "Epoch 45/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8470 - precision_9: 0.8161 - recall_9: 0.8905\n",
            "Epoch 46/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8466 - precision_9: 0.8139 - recall_9: 0.8932\n",
            "Epoch 47/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8501 - precision_9: 0.8167 - recall_9: 0.8977\n",
            "Epoch 48/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8468 - precision_9: 0.8115 - recall_9: 0.8981\n",
            "Epoch 49/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8591 - precision_9: 0.8241 - recall_9: 0.9084\n",
            "Epoch 50/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8558 - precision_9: 0.8235 - recall_9: 0.9008\n",
            "Epoch 51/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8430 - precision_9: 0.8084 - recall_9: 0.8937\n",
            "Epoch 52/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8494 - precision_9: 0.8172 - recall_9: 0.8950\n",
            "Epoch 53/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8505 - precision_9: 0.8153 - recall_9: 0.9013\n",
            "Epoch 54/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8512 - precision_9: 0.8165 - recall_9: 0.9008\n",
            "Epoch 55/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8494 - precision_9: 0.8183 - recall_9: 0.8932\n",
            "Epoch 56/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8534 - precision_9: 0.8212 - recall_9: 0.8986\n",
            "Epoch 57/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8485 - precision_9: 0.8211 - recall_9: 0.8861\n",
            "Epoch 58/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8591 - precision_9: 0.8215 - recall_9: 0.9129\n",
            "Epoch 59/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8536 - precision_9: 0.8228 - recall_9: 0.8963\n",
            "Epoch 60/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8567 - precision_9: 0.8278 - recall_9: 0.8959\n",
            "Epoch 61/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8571 - precision_9: 0.8274 - recall_9: 0.8977\n",
            "Epoch 62/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8536 - precision_9: 0.8204 - recall_9: 0.9004\n",
            "Epoch 63/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8596 - precision_9: 0.8269 - recall_9: 0.9048\n",
            "Epoch 64/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8569 - precision_9: 0.8242 - recall_9: 0.9026\n",
            "Epoch 65/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8629 - precision_9: 0.8311 - recall_9: 0.9062\n",
            "Epoch 66/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8668 - precision_9: 0.8359 - recall_9: 0.9084\n",
            "Epoch 67/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8638 - precision_9: 0.8320 - recall_9: 0.9071\n",
            "Epoch 68/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8552 - precision_9: 0.8217 - recall_9: 0.9021\n",
            "Epoch 69/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.8633 - precision_9: 0.8318 - recall_9: 0.9062\n",
            "Epoch 70/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3178 - accuracy: 0.8631 - precision_9: 0.8277 - recall_9: 0.9124\n",
            "Epoch 71/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3230 - accuracy: 0.8611 - precision_9: 0.8282 - recall_9: 0.9066\n",
            "Epoch 72/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8596 - precision_9: 0.8290 - recall_9: 0.9013\n",
            "Epoch 73/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8593 - precision_9: 0.8239 - recall_9: 0.9093\n",
            "Epoch 74/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8664 - precision_9: 0.8380 - recall_9: 0.9039\n",
            "Epoch 75/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8629 - precision_9: 0.8309 - recall_9: 0.9066\n",
            "Epoch 76/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8651 - precision_9: 0.8346 - recall_9: 0.9062\n",
            "Epoch 77/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8706 - precision_9: 0.8349 - recall_9: 0.9196\n",
            "Epoch 78/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8719 - precision_9: 0.8367 - recall_9: 0.9200\n",
            "Epoch 79/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8675 - precision_9: 0.8403 - recall_9: 0.9030\n",
            "Epoch 80/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8699 - precision_9: 0.8347 - recall_9: 0.9182\n",
            "Epoch 81/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8660 - precision_9: 0.8263 - recall_9: 0.9223\n",
            "Epoch 82/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8629 - precision_9: 0.8353 - recall_9: 0.8995\n",
            "Epoch 83/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3107 - accuracy: 0.8724 - precision_9: 0.8409 - recall_9: 0.9142\n",
            "Epoch 84/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8655 - precision_9: 0.8298 - recall_9: 0.9151\n",
            "Epoch 85/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8638 - precision_9: 0.8320 - recall_9: 0.9071\n",
            "Epoch 86/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8761 - precision_9: 0.8440 - recall_9: 0.9187\n",
            "Epoch 87/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8710 - precision_9: 0.8403 - recall_9: 0.9120\n",
            "Epoch 88/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8686 - precision_9: 0.8348 - recall_9: 0.9147\n",
            "Epoch 89/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8684 - precision_9: 0.8378 - recall_9: 0.9093\n",
            "Epoch 90/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8684 - precision_9: 0.8350 - recall_9: 0.9138\n",
            "Epoch 91/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8724 - precision_9: 0.8398 - recall_9: 0.9160\n",
            "Epoch 92/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8640 - precision_9: 0.8340 - recall_9: 0.9044\n",
            "Epoch 93/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.8684 - precision_9: 0.8334 - recall_9: 0.9164\n",
            "Epoch 94/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8717 - precision_9: 0.8407 - recall_9: 0.9129\n",
            "Epoch 95/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8770 - precision_9: 0.8429 - recall_9: 0.9227\n",
            "Epoch 96/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8655 - precision_9: 0.8358 - recall_9: 0.9053\n",
            "Epoch 97/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8717 - precision_9: 0.8405 - recall_9: 0.9133\n",
            "Epoch 98/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8664 - precision_9: 0.8369 - recall_9: 0.9057\n",
            "Epoch 99/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8785 - precision_9: 0.8470 - recall_9: 0.9200\n",
            "Epoch 100/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.8741 - precision_9: 0.8412 - recall_9: 0.9182\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8695 - precision_9: 0.8300 - recall_9: 0.9328\n",
            "[CV 1/3] END .........batch_size=50, epochs=100;, score=0.870 total time=  44.1s\n",
            "Epoch 1/100\n",
            "91/91 [==============================] - 2s 3ms/step - loss: 0.6337 - accuracy: 0.6365 - precision_10: 0.6137 - recall_10: 0.7629\n",
            "Epoch 2/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7492 - precision_10: 0.7196 - recall_10: 0.8273\n",
            "Epoch 3/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7688 - precision_10: 0.7332 - recall_10: 0.8547\n",
            "Epoch 4/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7803 - precision_10: 0.7444 - recall_10: 0.8625\n",
            "Epoch 5/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7950 - precision_10: 0.7561 - recall_10: 0.8791\n",
            "Epoch 6/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7822 - precision_10: 0.7505 - recall_10: 0.8543\n",
            "Epoch 7/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7919 - precision_10: 0.7603 - recall_10: 0.8608\n",
            "Epoch 8/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7959 - precision_10: 0.7611 - recall_10: 0.8704\n",
            "Epoch 9/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7994 - precision_10: 0.7622 - recall_10: 0.8782\n",
            "Epoch 10/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8019 - precision_10: 0.7662 - recall_10: 0.8765\n",
            "Epoch 11/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8045 - precision_10: 0.7715 - recall_10: 0.8726\n",
            "Epoch 12/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8063 - precision_10: 0.7716 - recall_10: 0.8773\n",
            "Epoch 13/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8133 - precision_10: 0.7790 - recall_10: 0.8817\n",
            "Epoch 14/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8164 - precision_10: 0.7819 - recall_10: 0.8843\n",
            "Epoch 15/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8133 - precision_10: 0.7767 - recall_10: 0.8865\n",
            "Epoch 16/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8124 - precision_10: 0.7800 - recall_10: 0.8773\n",
            "Epoch 17/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8102 - precision_10: 0.7785 - recall_10: 0.8743\n",
            "Epoch 18/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8157 - precision_10: 0.7791 - recall_10: 0.8882\n",
            "Epoch 19/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8138 - precision_10: 0.7779 - recall_10: 0.8852\n",
            "Epoch 20/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8140 - precision_10: 0.7834 - recall_10: 0.8747\n",
            "Epoch 21/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8235 - precision_10: 0.7876 - recall_10: 0.8921\n",
            "Epoch 22/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8177 - precision_10: 0.7877 - recall_10: 0.8765\n",
            "Epoch 23/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8292 - precision_10: 0.7924 - recall_10: 0.8982\n",
            "Epoch 24/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8252 - precision_10: 0.7912 - recall_10: 0.8900\n",
            "Epoch 25/100\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8329 - precision_10: 0.7990 - recall_10: 0.8956\n",
            "Epoch 26/100\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3820 - accuracy: 0.8323 - precision_10: 0.7992 - recall_10: 0.8934\n",
            "Epoch 27/100\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3849 - accuracy: 0.8292 - precision_10: 0.7977 - recall_10: 0.8882\n",
            "Epoch 28/100\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3816 - accuracy: 0.8303 - precision_10: 0.8016 - recall_10: 0.8839\n",
            "Epoch 29/100\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.3791 - accuracy: 0.8360 - precision_10: 0.8065 - recall_10: 0.8900\n",
            "Epoch 30/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8376 - precision_10: 0.8037 - recall_10: 0.8991\n",
            "Epoch 31/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8334 - precision_10: 0.8027 - recall_10: 0.8900\n",
            "Epoch 32/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8294 - precision_10: 0.8039 - recall_10: 0.8773\n",
            "Epoch 33/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8389 - precision_10: 0.8114 - recall_10: 0.8886\n",
            "Epoch 34/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8393 - precision_10: 0.8054 - recall_10: 0.9004\n",
            "Epoch 35/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8334 - precision_10: 0.8058 - recall_10: 0.8843\n",
            "Epoch 36/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8373 - precision_10: 0.8106 - recall_10: 0.8860\n",
            "Epoch 37/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8389 - precision_10: 0.8087 - recall_10: 0.8934\n",
            "Epoch 38/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8404 - precision_10: 0.8134 - recall_10: 0.8891\n",
            "Epoch 39/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8422 - precision_10: 0.8095 - recall_10: 0.9004\n",
            "Epoch 40/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8455 - precision_10: 0.8116 - recall_10: 0.9052\n",
            "Epoch 41/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8413 - precision_10: 0.8061 - recall_10: 0.9043\n",
            "Epoch 42/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8464 - precision_10: 0.8166 - recall_10: 0.8987\n",
            "Epoch 43/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8387 - precision_10: 0.8093 - recall_10: 0.8917\n",
            "Epoch 44/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8417 - precision_10: 0.8138 - recall_10: 0.8917\n",
            "Epoch 45/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8497 - precision_10: 0.8164 - recall_10: 0.9074\n",
            "Epoch 46/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8506 - precision_10: 0.8202 - recall_10: 0.9030\n",
            "Epoch 47/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8446 - precision_10: 0.8183 - recall_10: 0.8913\n",
            "Epoch 48/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8442 - precision_10: 0.8119 - recall_10: 0.9013\n",
            "Epoch 49/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8514 - precision_10: 0.8244 - recall_10: 0.8982\n",
            "Epoch 50/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3455 - accuracy: 0.8495 - precision_10: 0.8191 - recall_10: 0.9021\n",
            "Epoch 51/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3393 - accuracy: 0.8481 - precision_10: 0.8159 - recall_10: 0.9043\n",
            "Epoch 52/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3377 - accuracy: 0.8572 - precision_10: 0.8295 - recall_10: 0.9039\n",
            "Epoch 53/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3391 - accuracy: 0.8532 - precision_10: 0.8181 - recall_10: 0.9134\n",
            "Epoch 54/100\n",
            "91/91 [==============================] - 1s 11ms/step - loss: 0.3379 - accuracy: 0.8552 - precision_10: 0.8240 - recall_10: 0.9082\n",
            "Epoch 55/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3345 - accuracy: 0.8587 - precision_10: 0.8251 - recall_10: 0.9152\n",
            "Epoch 56/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3351 - accuracy: 0.8532 - precision_10: 0.8262 - recall_10: 0.8995\n",
            "Epoch 57/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8550 - precision_10: 0.8278 - recall_10: 0.9013\n",
            "Epoch 58/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8583 - precision_10: 0.8257 - recall_10: 0.9130\n",
            "Epoch 59/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8539 - precision_10: 0.8243 - recall_10: 0.9043\n",
            "Epoch 60/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8567 - precision_10: 0.8252 - recall_10: 0.9100\n",
            "Epoch 61/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8508 - precision_10: 0.8211 - recall_10: 0.9021\n",
            "Epoch 62/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8565 - precision_10: 0.8265 - recall_10: 0.9074\n",
            "Epoch 63/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8572 - precision_10: 0.8269 - recall_10: 0.9082\n",
            "Epoch 64/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8567 - precision_10: 0.8260 - recall_10: 0.9087\n",
            "Epoch 65/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8521 - precision_10: 0.8207 - recall_10: 0.9060\n",
            "Epoch 66/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8594 - precision_10: 0.8313 - recall_10: 0.9065\n",
            "Epoch 67/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8574 - precision_10: 0.8247 - recall_10: 0.9126\n",
            "Epoch 68/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8464 - precision_10: 0.8186 - recall_10: 0.8952\n",
            "Epoch 69/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8658 - precision_10: 0.8343 - recall_10: 0.9174\n",
            "Epoch 70/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8589 - precision_10: 0.8244 - recall_10: 0.9169\n",
            "Epoch 71/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8631 - precision_10: 0.8295 - recall_10: 0.9187\n",
            "Epoch 72/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8678 - precision_10: 0.8375 - recall_10: 0.9169\n",
            "Epoch 73/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8647 - precision_10: 0.8371 - recall_10: 0.9100\n",
            "Epoch 74/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8567 - precision_10: 0.8265 - recall_10: 0.9078\n",
            "Epoch 75/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8607 - precision_10: 0.8309 - recall_10: 0.9104\n",
            "Epoch 76/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8587 - precision_10: 0.8272 - recall_10: 0.9117\n",
            "Epoch 77/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8587 - precision_10: 0.8251 - recall_10: 0.9152\n",
            "Epoch 78/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8627 - precision_10: 0.8315 - recall_10: 0.9143\n",
            "Epoch 79/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8622 - precision_10: 0.8295 - recall_10: 0.9165\n",
            "Epoch 80/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8616 - precision_10: 0.8333 - recall_10: 0.9087\n",
            "Epoch 81/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8662 - precision_10: 0.8336 - recall_10: 0.9195\n",
            "Epoch 82/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8664 - precision_10: 0.8412 - recall_10: 0.9078\n",
            "Epoch 83/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8717 - precision_10: 0.8397 - recall_10: 0.9230\n",
            "Epoch 84/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.8711 - precision_10: 0.8412 - recall_10: 0.9191\n",
            "Epoch 85/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8702 - precision_10: 0.8436 - recall_10: 0.9130\n",
            "Epoch 86/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8640 - precision_10: 0.8353 - recall_10: 0.9113\n",
            "Epoch 87/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8620 - precision_10: 0.8339 - recall_10: 0.9087\n",
            "Epoch 88/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8636 - precision_10: 0.8390 - recall_10: 0.9043\n",
            "Epoch 89/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8607 - precision_10: 0.8314 - recall_10: 0.9095\n",
            "Epoch 90/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8675 - precision_10: 0.8388 - recall_10: 0.9143\n",
            "Epoch 91/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8686 - precision_10: 0.8370 - recall_10: 0.9200\n",
            "Epoch 92/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8620 - precision_10: 0.8350 - recall_10: 0.9069\n",
            "Epoch 93/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8728 - precision_10: 0.8450 - recall_10: 0.9174\n",
            "Epoch 94/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8680 - precision_10: 0.8416 - recall_10: 0.9108\n",
            "Epoch 95/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.8598 - precision_10: 0.8309 - recall_10: 0.9082\n",
            "Epoch 96/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8673 - precision_10: 0.8387 - recall_10: 0.9139\n",
            "Epoch 97/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8682 - precision_10: 0.8420 - recall_10: 0.9108\n",
            "Epoch 98/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8669 - precision_10: 0.8367 - recall_10: 0.9161\n",
            "Epoch 99/100\n",
            "91/91 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8700 - precision_10: 0.8406 - recall_10: 0.9174\n",
            "Epoch 100/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8655 - precision_10: 0.8361 - recall_10: 0.9139\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8602 - precision_10: 0.8092 - recall_10: 0.9263\n",
            "[CV 2/3] END .........batch_size=50, epochs=100;, score=0.860 total time=  43.7s\n",
            "Epoch 1/100\n",
            "91/91 [==============================] - 2s 4ms/step - loss: 0.6472 - accuracy: 0.6291 - precision_11: 0.5798 - recall_11: 0.8920\n",
            "Epoch 2/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7143 - precision_11: 0.6478 - recall_11: 0.9184\n",
            "Epoch 3/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7580 - precision_11: 0.7025 - recall_11: 0.8808\n",
            "Epoch 4/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7725 - precision_11: 0.7246 - recall_11: 0.8669\n",
            "Epoch 5/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7785 - precision_11: 0.7291 - recall_11: 0.8745\n",
            "Epoch 6/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7866 - precision_11: 0.7409 - recall_11: 0.8705\n",
            "Epoch 7/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7849 - precision_11: 0.7427 - recall_11: 0.8606\n",
            "Epoch 8/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7966 - precision_11: 0.7539 - recall_11: 0.8705\n",
            "Epoch 9/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7924 - precision_11: 0.7497 - recall_11: 0.8673\n",
            "Epoch 10/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7972 - precision_11: 0.7606 - recall_11: 0.8575\n",
            "Epoch 11/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7983 - precision_11: 0.7562 - recall_11: 0.8705\n",
            "Epoch 12/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8067 - precision_11: 0.7695 - recall_11: 0.8664\n",
            "Epoch 13/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8085 - precision_11: 0.7715 - recall_11: 0.8673\n",
            "Epoch 14/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8080 - precision_11: 0.7735 - recall_11: 0.8619\n",
            "Epoch 15/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8113 - precision_11: 0.7655 - recall_11: 0.8884\n",
            "Epoch 16/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8082 - precision_11: 0.7799 - recall_11: 0.8498\n",
            "Epoch 17/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8107 - precision_11: 0.7780 - recall_11: 0.8606\n",
            "Epoch 18/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8138 - precision_11: 0.7776 - recall_11: 0.8700\n",
            "Epoch 19/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8206 - precision_11: 0.7851 - recall_11: 0.8745\n",
            "Epoch 20/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8100 - precision_11: 0.7800 - recall_11: 0.8548\n",
            "Epoch 21/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8135 - precision_11: 0.7846 - recall_11: 0.8557\n",
            "Epoch 22/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8127 - precision_11: 0.7806 - recall_11: 0.8610\n",
            "Epoch 23/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8246 - precision_11: 0.7873 - recall_11: 0.8812\n",
            "Epoch 24/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8168 - precision_11: 0.7804 - recall_11: 0.8732\n",
            "Epoch 25/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8292 - precision_11: 0.7998 - recall_11: 0.8705\n",
            "Epoch 26/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8235 - precision_11: 0.7862 - recall_11: 0.8803\n",
            "Epoch 27/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8232 - precision_11: 0.7878 - recall_11: 0.8767\n",
            "Epoch 28/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8219 - precision_11: 0.7831 - recall_11: 0.8821\n",
            "Epoch 29/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8246 - precision_11: 0.7851 - recall_11: 0.8857\n",
            "Epoch 30/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8195 - precision_11: 0.7808 - recall_11: 0.8799\n",
            "Epoch 31/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8285 - precision_11: 0.7828 - recall_11: 0.9014\n",
            "Epoch 32/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8314 - precision_11: 0.7975 - recall_11: 0.8808\n",
            "Epoch 33/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8250 - precision_11: 0.7931 - recall_11: 0.8714\n",
            "Epoch 34/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.8307 - precision_11: 0.7911 - recall_11: 0.8911\n",
            "Epoch 35/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8305 - precision_11: 0.7903 - recall_11: 0.8920\n",
            "Epoch 36/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.8351 - precision_11: 0.7970 - recall_11: 0.8920\n",
            "Epoch 37/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8301 - precision_11: 0.7913 - recall_11: 0.8888\n",
            "Epoch 38/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8316 - precision_11: 0.7933 - recall_11: 0.8893\n",
            "Epoch 39/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8298 - precision_11: 0.7875 - recall_11: 0.8956\n",
            "Epoch 40/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8343 - precision_11: 0.7883 - recall_11: 0.9063\n",
            "Epoch 41/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8334 - precision_11: 0.7916 - recall_11: 0.8974\n",
            "Epoch 42/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8320 - precision_11: 0.7911 - recall_11: 0.8947\n",
            "Epoch 43/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8358 - precision_11: 0.7944 - recall_11: 0.8987\n",
            "Epoch 44/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8252 - precision_11: 0.7871 - recall_11: 0.8835\n",
            "Epoch 45/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8331 - precision_11: 0.7932 - recall_11: 0.8938\n",
            "Epoch 46/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8347 - precision_11: 0.7994 - recall_11: 0.8861\n",
            "Epoch 47/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8327 - precision_11: 0.7889 - recall_11: 0.9009\n",
            "Epoch 48/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8420 - precision_11: 0.8014 - recall_11: 0.9023\n",
            "Epoch 49/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8343 - precision_11: 0.7962 - recall_11: 0.8911\n",
            "Epoch 50/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8360 - precision_11: 0.8029 - recall_11: 0.8835\n",
            "Epoch 51/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8420 - precision_11: 0.8050 - recall_11: 0.8956\n",
            "Epoch 52/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8389 - precision_11: 0.8010 - recall_11: 0.8947\n",
            "Epoch 53/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8402 - precision_11: 0.8022 - recall_11: 0.8960\n",
            "Epoch 54/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8420 - precision_11: 0.8072 - recall_11: 0.8915\n",
            "Epoch 55/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8382 - precision_11: 0.8029 - recall_11: 0.8893\n",
            "Epoch 56/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8428 - precision_11: 0.8024 - recall_11: 0.9027\n",
            "Epoch 57/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8464 - precision_11: 0.8128 - recall_11: 0.8933\n",
            "Epoch 58/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8431 - precision_11: 0.8069 - recall_11: 0.8951\n",
            "Epoch 59/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8373 - precision_11: 0.8031 - recall_11: 0.8866\n",
            "Epoch 60/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8446 - precision_11: 0.8062 - recall_11: 0.9005\n",
            "Epoch 61/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8345 - precision_11: 0.7951 - recall_11: 0.8938\n",
            "Epoch 62/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8495 - precision_11: 0.8123 - recall_11: 0.9023\n",
            "Epoch 63/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8470 - precision_11: 0.8068 - recall_11: 0.9059\n",
            "Epoch 64/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8398 - precision_11: 0.7937 - recall_11: 0.9108\n",
            "Epoch 65/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8475 - precision_11: 0.8065 - recall_11: 0.9077\n",
            "Epoch 66/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8439 - precision_11: 0.8057 - recall_11: 0.8996\n",
            "Epoch 67/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8455 - precision_11: 0.8075 - recall_11: 0.9005\n",
            "Epoch 68/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8435 - precision_11: 0.8036 - recall_11: 0.9023\n",
            "Epoch 69/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8499 - precision_11: 0.8181 - recall_11: 0.8933\n",
            "Epoch 70/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8499 - precision_11: 0.8051 - recall_11: 0.9166\n",
            "Epoch 71/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8457 - precision_11: 0.8058 - recall_11: 0.9041\n",
            "Epoch 72/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8413 - precision_11: 0.8045 - recall_11: 0.8947\n",
            "Epoch 73/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8442 - precision_11: 0.8043 - recall_11: 0.9027\n",
            "Epoch 74/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8462 - precision_11: 0.8060 - recall_11: 0.9050\n",
            "Epoch 75/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8444 - precision_11: 0.8056 - recall_11: 0.9009\n",
            "Epoch 76/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8437 - precision_11: 0.7973 - recall_11: 0.9148\n",
            "Epoch 77/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8492 - precision_11: 0.8118 - recall_11: 0.9027\n",
            "Epoch 78/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8426 - precision_11: 0.8023 - recall_11: 0.9023\n",
            "Epoch 79/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8545 - precision_11: 0.8141 - recall_11: 0.9126\n",
            "Epoch 80/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8389 - precision_11: 0.8012 - recall_11: 0.8942\n",
            "Epoch 81/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8484 - precision_11: 0.8143 - recall_11: 0.8960\n",
            "Epoch 82/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8453 - precision_11: 0.8028 - recall_11: 0.9086\n",
            "Epoch 83/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8488 - precision_11: 0.8074 - recall_11: 0.9095\n",
            "Epoch 84/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8499 - precision_11: 0.8073 - recall_11: 0.9126\n",
            "Epoch 85/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8510 - precision_11: 0.8077 - recall_11: 0.9148\n",
            "Epoch 86/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8556 - precision_11: 0.8167 - recall_11: 0.9108\n",
            "Epoch 87/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.8530 - precision_11: 0.8118 - recall_11: 0.9126\n",
            "Epoch 88/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8600 - precision_11: 0.8215 - recall_11: 0.9139\n",
            "Epoch 89/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8585 - precision_11: 0.8179 - recall_11: 0.9162\n",
            "Epoch 90/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8545 - precision_11: 0.8143 - recall_11: 0.9121\n",
            "Epoch 91/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.3134 - accuracy: 0.8572 - precision_11: 0.8193 - recall_11: 0.9104\n",
            "Epoch 92/100\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.3205 - accuracy: 0.8508 - precision_11: 0.8136 - recall_11: 0.9036\n",
            "Epoch 93/100\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.3237 - accuracy: 0.8481 - precision_11: 0.8152 - recall_11: 0.8938\n",
            "Epoch 94/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.3050 - accuracy: 0.8653 - precision_11: 0.8285 - recall_11: 0.9157\n",
            "Epoch 95/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8563 - precision_11: 0.8172 - recall_11: 0.9117\n",
            "Epoch 96/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8543 - precision_11: 0.8212 - recall_11: 0.8996\n",
            "Epoch 97/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8545 - precision_11: 0.8166 - recall_11: 0.9081\n",
            "Epoch 98/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8583 - precision_11: 0.8228 - recall_11: 0.9072\n",
            "Epoch 99/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8455 - precision_11: 0.8077 - recall_11: 0.9000\n",
            "Epoch 100/100\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8581 - precision_11: 0.8135 - recall_11: 0.9229\n",
            "46/46 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8496 - precision_11: 0.8128 - recall_11: 0.9150\n",
            "[CV 3/3] END .........batch_size=50, epochs=100;, score=0.850 total time=  41.4s\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 2s 3ms/step - loss: 0.7172 - accuracy: 0.5317 - precision_12: 0.5175 - recall_12: 0.7534\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6918 - precision_12: 0.6417 - recall_12: 0.8499\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7421 - precision_12: 0.6793 - recall_12: 0.9039\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7740 - precision_12: 0.7117 - recall_12: 0.9111\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7840 - precision_12: 0.7230 - recall_12: 0.9111\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7873 - precision_12: 0.7326 - recall_12: 0.8959\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7881 - precision_12: 0.7367 - recall_12: 0.8878\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7976 - precision_12: 0.7491 - recall_12: 0.8870\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8020 - precision_12: 0.7571 - recall_12: 0.8816\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8000 - precision_12: 0.7613 - recall_12: 0.8664\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8053 - precision_12: 0.7733 - recall_12: 0.8566\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8106 - precision_12: 0.7746 - recall_12: 0.8691\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8142 - precision_12: 0.7805 - recall_12: 0.8673\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8095 - precision_12: 0.7802 - recall_12: 0.8548\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8108 - precision_12: 0.7798 - recall_12: 0.8592\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8190 - precision_12: 0.7891 - recall_12: 0.8642\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8190 - precision_12: 0.7948 - recall_12: 0.8534\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8194 - precision_12: 0.7957 - recall_12: 0.8530\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8133 - precision_12: 0.7831 - recall_12: 0.8597\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8190 - precision_12: 0.7910 - recall_12: 0.8606\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8228 - precision_12: 0.7963 - recall_12: 0.8610\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.8285 - precision_12: 0.7980 - recall_12: 0.8735\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8298 - precision_12: 0.8052 - recall_12: 0.8642\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8265 - precision_12: 0.8007 - recall_12: 0.8633\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8347 - precision_12: 0.8039 - recall_12: 0.8794\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8355 - precision_12: 0.8040 - recall_12: 0.8816\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8269 - precision_12: 0.7947 - recall_12: 0.8753\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8340 - precision_12: 0.8052 - recall_12: 0.8753\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8287 - precision_12: 0.7995 - recall_12: 0.8713\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8340 - precision_12: 0.8052 - recall_12: 0.8753\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8313 - precision_12: 0.8067 - recall_12: 0.8655\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8413 - precision_12: 0.8100 - recall_12: 0.8861\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8391 - precision_12: 0.8053 - recall_12: 0.8887\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8285 - precision_12: 0.8017 - recall_12: 0.8668\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8419 - precision_12: 0.8029 - recall_12: 0.9008\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8395 - precision_12: 0.8084 - recall_12: 0.8843\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8441 - precision_12: 0.8103 - recall_12: 0.8932\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8358 - precision_12: 0.8002 - recall_12: 0.8892\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8406 - precision_12: 0.8083 - recall_12: 0.8874\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8419 - precision_12: 0.8090 - recall_12: 0.8896\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8410 - precision_12: 0.8062 - recall_12: 0.8923\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8452 - precision_12: 0.8097 - recall_12: 0.8972\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8530 - precision_12: 0.8213 - recall_12: 0.8972\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8490 - precision_12: 0.8120 - recall_12: 0.9030\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8461 - precision_12: 0.8048 - recall_12: 0.9084\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8485 - precision_12: 0.8091 - recall_12: 0.9071\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8556 - precision_12: 0.8177 - recall_12: 0.9102\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8479 - precision_12: 0.8113 - recall_12: 0.9013\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8496 - precision_12: 0.8142 - recall_12: 0.9008\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8514 - precision_12: 0.8131 - recall_12: 0.9075\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8347 - precision_12: 0.7995 - recall_12: 0.8979\n",
            "[CV 1/3] END .........batch_size=100, epochs=50;, score=0.835 total time=  12.9s\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 2s 4ms/step - loss: 0.6582 - accuracy: 0.6253 - precision_13: 0.6011 - recall_13: 0.7747\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7518 - precision_13: 0.7054 - recall_13: 0.8760\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7701 - precision_13: 0.7309 - recall_13: 0.8647\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7767 - precision_13: 0.7345 - recall_13: 0.8760\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7893 - precision_13: 0.7446 - recall_13: 0.8891\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7959 - precision_13: 0.7483 - recall_13: 0.9000\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7913 - precision_13: 0.7432 - recall_13: 0.8987\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.8003 - precision_13: 0.7526 - recall_13: 0.9026\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8032 - precision_13: 0.7555 - recall_13: 0.9043\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8069 - precision_13: 0.7603 - recall_13: 0.9039\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8076 - precision_13: 0.7598 - recall_13: 0.9069\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.8076 - precision_13: 0.7604 - recall_13: 0.9056\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8144 - precision_13: 0.7629 - recall_13: 0.9195\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8118 - precision_13: 0.7687 - recall_13: 0.8991\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8193 - precision_13: 0.7694 - recall_13: 0.9187\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8246 - precision_13: 0.7762 - recall_13: 0.9187\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8226 - precision_13: 0.7738 - recall_13: 0.9182\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8248 - precision_13: 0.7775 - recall_13: 0.9165\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8217 - precision_13: 0.7753 - recall_13: 0.9126\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8263 - precision_13: 0.7770 - recall_13: 0.9217\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8329 - precision_13: 0.7851 - recall_13: 0.9230\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8329 - precision_13: 0.7846 - recall_13: 0.9239\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8259 - precision_13: 0.7773 - recall_13: 0.9200\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8387 - precision_13: 0.7879 - recall_13: 0.9326\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8347 - precision_13: 0.7882 - recall_13: 0.9213\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8338 - precision_13: 0.7877 - recall_13: 0.9200\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8316 - precision_13: 0.7821 - recall_13: 0.9256\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8312 - precision_13: 0.7836 - recall_13: 0.9213\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8354 - precision_13: 0.7853 - recall_13: 0.9291\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8351 - precision_13: 0.7878 - recall_13: 0.9234\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8369 - precision_13: 0.7829 - recall_13: 0.9382\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8369 - precision_13: 0.7932 - recall_13: 0.9174\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8400 - precision_13: 0.7936 - recall_13: 0.9247\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8455 - precision_13: 0.8015 - recall_13: 0.9239\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8354 - precision_13: 0.7906 - recall_13: 0.9182\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8404 - precision_13: 0.7957 - recall_13: 0.9217\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8420 - precision_13: 0.7989 - recall_13: 0.9195\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8444 - precision_13: 0.7962 - recall_13: 0.9313\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8486 - precision_13: 0.8007 - recall_13: 0.9334\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8492 - precision_13: 0.8074 - recall_13: 0.9226\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8479 - precision_13: 0.8065 - recall_13: 0.9208\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8550 - precision_13: 0.8133 - recall_13: 0.9265\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8570 - precision_13: 0.8149 - recall_13: 0.9287\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8541 - precision_13: 0.8109 - recall_13: 0.9287\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8477 - precision_13: 0.8062 - recall_13: 0.9208\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8501 - precision_13: 0.8074 - recall_13: 0.9247\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8521 - precision_13: 0.8153 - recall_13: 0.9156\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8514 - precision_13: 0.8114 - recall_13: 0.9208\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8536 - precision_13: 0.8110 - recall_13: 0.9274\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8642 - precision_13: 0.8255 - recall_13: 0.9282\n",
            "23/23 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8369 - precision_13: 0.7800 - recall_13: 0.9180\n",
            "[CV 2/3] END .........batch_size=100, epochs=50;, score=0.837 total time=  23.3s\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 3s 4ms/step - loss: 0.6264 - accuracy: 0.6555 - precision_14: 0.6182 - recall_14: 0.7831\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7417 - precision_14: 0.6916 - recall_14: 0.8566\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7701 - precision_14: 0.7255 - recall_14: 0.8566\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7853 - precision_14: 0.7378 - recall_14: 0.8740\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.8014 - precision_14: 0.7506 - recall_14: 0.8929\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8010 - precision_14: 0.7525 - recall_14: 0.8870\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8115 - precision_14: 0.7616 - recall_14: 0.8978\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8168 - precision_14: 0.7728 - recall_14: 0.8888\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8146 - precision_14: 0.7708 - recall_14: 0.8866\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8151 - precision_14: 0.7704 - recall_14: 0.8888\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8186 - precision_14: 0.7763 - recall_14: 0.8866\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8248 - precision_14: 0.7816 - recall_14: 0.8933\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8343 - precision_14: 0.7901 - recall_14: 0.9027\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8327 - precision_14: 0.7866 - recall_14: 0.9054\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8371 - precision_14: 0.7944 - recall_14: 0.9023\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8369 - precision_14: 0.7967 - recall_14: 0.8974\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8345 - precision_14: 0.7934 - recall_14: 0.8969\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8340 - precision_14: 0.7928 - recall_14: 0.8969\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8406 - precision_14: 0.8016 - recall_14: 0.8983\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.8466 - precision_14: 0.8061 - recall_14: 0.9059\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3551 - accuracy: 0.8433 - precision_14: 0.8052 - recall_14: 0.8987\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8484 - precision_14: 0.8112 - recall_14: 0.9014\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8497 - precision_14: 0.8102 - recall_14: 0.9068\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8497 - precision_14: 0.8134 - recall_14: 0.9009\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.3436 - accuracy: 0.8572 - precision_14: 0.8190 - recall_14: 0.9108\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.3439 - accuracy: 0.8503 - precision_14: 0.8129 - recall_14: 0.9036\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.8581 - precision_14: 0.8224 - recall_14: 0.9072\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.3458 - accuracy: 0.8523 - precision_14: 0.8084 - recall_14: 0.9171\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.3419 - accuracy: 0.8572 - precision_14: 0.8243 - recall_14: 0.9018\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 11ms/step - loss: 0.3395 - accuracy: 0.8581 - precision_14: 0.8173 - recall_14: 0.9162\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8605 - precision_14: 0.8222 - recall_14: 0.9139\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 1s 12ms/step - loss: 0.3389 - accuracy: 0.8545 - precision_14: 0.8205 - recall_14: 0.9014\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.3413 - accuracy: 0.8561 - precision_14: 0.8192 - recall_14: 0.9077\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 7ms/step - loss: 0.3262 - accuracy: 0.8647 - precision_14: 0.8280 - recall_14: 0.9148\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8616 - precision_14: 0.8292 - recall_14: 0.9050\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8563 - precision_14: 0.8114 - recall_14: 0.9220\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3231 - accuracy: 0.8640 - precision_14: 0.8291 - recall_14: 0.9113\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8633 - precision_14: 0.8303 - recall_14: 0.9077\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8669 - precision_14: 0.8274 - recall_14: 0.9216\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8691 - precision_14: 0.8323 - recall_14: 0.9189\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3213 - accuracy: 0.8680 - precision_14: 0.8304 - recall_14: 0.9193\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8655 - precision_14: 0.8304 - recall_14: 0.9130\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.8678 - precision_14: 0.8316 - recall_14: 0.9166\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8730 - precision_14: 0.8390 - recall_14: 0.9180\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3165 - accuracy: 0.8702 - precision_14: 0.8297 - recall_14: 0.9260\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8647 - precision_14: 0.8293 - recall_14: 0.9126\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3100 - accuracy: 0.8777 - precision_14: 0.8395 - recall_14: 0.9287\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8708 - precision_14: 0.8305 - recall_14: 0.9265\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8708 - precision_14: 0.8348 - recall_14: 0.9193\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8779 - precision_14: 0.8463 - recall_14: 0.9184\n",
            "23/23 [==============================] - 1s 4ms/step - loss: 0.3306 - accuracy: 0.8629 - precision_14: 0.8274 - recall_14: 0.9228\n",
            "[CV 3/3] END .........batch_size=100, epochs=50;, score=0.863 total time=  18.8s\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 3s 4ms/step - loss: 0.6978 - accuracy: 0.6030 - precision_15: 0.6925 - recall_15: 0.3512\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.6508 - precision_15: 0.7689 - recall_15: 0.4178\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.6865 - precision_15: 0.7760 - recall_15: 0.5125\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.7209 - precision_15: 0.7673 - recall_15: 0.6233\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7498 - precision_15: 0.7632 - recall_15: 0.7145\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7884 - precision_15: 0.7719 - recall_15: 0.8105\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7888 - precision_15: 0.7574 - recall_15: 0.8414\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7976 - precision_15: 0.7588 - recall_15: 0.8646\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8073 - precision_15: 0.7689 - recall_15: 0.8713\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.8071 - precision_15: 0.7684 - recall_15: 0.8718\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8053 - precision_15: 0.7627 - recall_15: 0.8789\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8086 - precision_15: 0.7609 - recall_15: 0.8928\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8133 - precision_15: 0.7660 - recall_15: 0.8950\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8192 - precision_15: 0.7746 - recall_15: 0.8937\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8225 - precision_15: 0.7763 - recall_15: 0.8995\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8177 - precision_15: 0.7744 - recall_15: 0.8896\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8223 - precision_15: 0.7780 - recall_15: 0.8954\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8278 - precision_15: 0.7792 - recall_15: 0.9084\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8278 - precision_15: 0.7801 - recall_15: 0.9066\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8377 - precision_15: 0.7913 - recall_15: 0.9115\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8384 - precision_15: 0.7898 - recall_15: 0.9164\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8369 - precision_15: 0.7901 - recall_15: 0.9115\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8388 - precision_15: 0.7926 - recall_15: 0.9120\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8362 - precision_15: 0.7863 - recall_15: 0.9173\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8369 - precision_15: 0.7901 - recall_15: 0.9115\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8408 - precision_15: 0.7902 - recall_15: 0.9223\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3528 - accuracy: 0.8439 - precision_15: 0.7961 - recall_15: 0.9191\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8488 - precision_15: 0.8019 - recall_15: 0.9209\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8433 - precision_15: 0.7979 - recall_15: 0.9138\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8395 - precision_15: 0.7949 - recall_15: 0.9093\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8481 - precision_15: 0.8043 - recall_15: 0.9147\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8492 - precision_15: 0.8061 - recall_15: 0.9142\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8457 - precision_15: 0.8028 - recall_15: 0.9111\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8532 - precision_15: 0.8035 - recall_15: 0.9298\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8485 - precision_15: 0.8040 - recall_15: 0.9164\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8565 - precision_15: 0.8123 - recall_15: 0.9223\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8574 - precision_15: 0.8082 - recall_15: 0.9321\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8543 - precision_15: 0.8118 - recall_15: 0.9173\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8593 - precision_15: 0.8142 - recall_15: 0.9263\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3252 - accuracy: 0.8585 - precision_15: 0.8197 - recall_15: 0.9142\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8649 - precision_15: 0.8225 - recall_15: 0.9258\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8602 - precision_15: 0.8175 - recall_15: 0.9227\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8598 - precision_15: 0.8194 - recall_15: 0.9182\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8633 - precision_15: 0.8200 - recall_15: 0.9263\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8633 - precision_15: 0.8257 - recall_15: 0.9164\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8664 - precision_15: 0.8259 - recall_15: 0.9240\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.8690 - precision_15: 0.8270 - recall_15: 0.9290\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8688 - precision_15: 0.8248 - recall_15: 0.9321\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8695 - precision_15: 0.8289 - recall_15: 0.9267\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8746 - precision_15: 0.8358 - recall_15: 0.9281\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3152 - accuracy: 0.8666 - precision_15: 0.8270 - recall_15: 0.9227\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8719 - precision_15: 0.8302 - recall_15: 0.9307\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8677 - precision_15: 0.8247 - recall_15: 0.9294\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3041 - accuracy: 0.8704 - precision_15: 0.8356 - recall_15: 0.9178\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.8655 - precision_15: 0.8280 - recall_15: 0.9182\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8732 - precision_15: 0.8319 - recall_15: 0.9312\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8717 - precision_15: 0.8304 - recall_15: 0.9298\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3042 - accuracy: 0.8748 - precision_15: 0.8414 - recall_15: 0.9196\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.8761 - precision_15: 0.8395 - recall_15: 0.9258\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.3030 - accuracy: 0.8710 - precision_15: 0.8315 - recall_15: 0.9263\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8759 - precision_15: 0.8341 - recall_15: 0.9343\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3009 - accuracy: 0.8765 - precision_15: 0.8419 - recall_15: 0.9231\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2933 - accuracy: 0.8752 - precision_15: 0.8341 - recall_15: 0.9325\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.8763 - precision_15: 0.8446 - recall_15: 0.9182\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3021 - accuracy: 0.8768 - precision_15: 0.8386 - recall_15: 0.9290\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8867 - precision_15: 0.8501 - recall_15: 0.9352\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3004 - accuracy: 0.8757 - precision_15: 0.8400 - recall_15: 0.9240\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.8774 - precision_15: 0.8397 - recall_15: 0.9290\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2895 - accuracy: 0.8794 - precision_15: 0.8461 - recall_15: 0.9236\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.8746 - precision_15: 0.8364 - recall_15: 0.9272\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8790 - precision_15: 0.8409 - recall_15: 0.9307\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8814 - precision_15: 0.8441 - recall_15: 0.9316\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.8821 - precision_15: 0.8454 - recall_15: 0.9312\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2833 - accuracy: 0.8840 - precision_15: 0.8466 - recall_15: 0.9343\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.8810 - precision_15: 0.8482 - recall_15: 0.9240\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2806 - accuracy: 0.8869 - precision_15: 0.8499 - recall_15: 0.9361\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2843 - accuracy: 0.8816 - precision_15: 0.8442 - recall_15: 0.9321\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2968 - accuracy: 0.8803 - precision_15: 0.8433 - recall_15: 0.9303\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.8849 - precision_15: 0.8491 - recall_15: 0.9325\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2872 - accuracy: 0.8810 - precision_15: 0.8451 - recall_15: 0.9290\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2826 - accuracy: 0.8847 - precision_15: 0.8462 - recall_15: 0.9366\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2834 - accuracy: 0.8851 - precision_15: 0.8514 - recall_15: 0.9294\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8876 - precision_15: 0.8527 - recall_15: 0.9334\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.8801 - precision_15: 0.8426 - recall_15: 0.9307\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2833 - accuracy: 0.8838 - precision_15: 0.8488 - recall_15: 0.9303\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2728 - accuracy: 0.8929 - precision_15: 0.8570 - recall_15: 0.9397\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.8926 - precision_15: 0.8555 - recall_15: 0.9415\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.8845 - precision_15: 0.8472 - recall_15: 0.9343\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2755 - accuracy: 0.8920 - precision_15: 0.8547 - recall_15: 0.9410\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2742 - accuracy: 0.8907 - precision_15: 0.8529 - recall_15: 0.9406\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2771 - accuracy: 0.8902 - precision_15: 0.8548 - recall_15: 0.9366\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2856 - accuracy: 0.8840 - precision_15: 0.8523 - recall_15: 0.9254\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 0s 6ms/step - loss: 0.2763 - accuracy: 0.8847 - precision_15: 0.8473 - recall_15: 0.9348\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2752 - accuracy: 0.8887 - precision_15: 0.8603 - recall_15: 0.9245\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.8904 - precision_15: 0.8529 - recall_15: 0.9401\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2791 - accuracy: 0.8900 - precision_15: 0.8516 - recall_15: 0.9410\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2788 - accuracy: 0.8887 - precision_15: 0.8524 - recall_15: 0.9366\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2655 - accuracy: 0.8951 - precision_15: 0.8567 - recall_15: 0.9455\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.8929 - precision_15: 0.8555 - recall_15: 0.9419\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.8880 - precision_15: 0.8533 - recall_15: 0.9334\n",
            "23/23 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8678 - precision_15: 0.8254 - recall_15: 0.9363\n",
            "[CV 1/3] END ........batch_size=100, epochs=100;, score=0.868 total time=  44.4s\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 2s 4ms/step - loss: 0.6216 - accuracy: 0.6581 - precision_16: 0.6312 - recall_16: 0.7825\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7589 - precision_16: 0.7208 - recall_16: 0.8556\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7847 - precision_16: 0.7508 - recall_16: 0.8608\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7926 - precision_16: 0.7564 - recall_16: 0.8712\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7974 - precision_16: 0.7622 - recall_16: 0.8726\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8069 - precision_16: 0.7721 - recall_16: 0.8782\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7992 - precision_16: 0.7657 - recall_16: 0.8699\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.8021 - precision_16: 0.7644 - recall_16: 0.8808\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8089 - precision_16: 0.7767 - recall_16: 0.8743\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8252 - precision_16: 0.7910 - recall_16: 0.8904\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8212 - precision_16: 0.7864 - recall_16: 0.8886\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8166 - precision_16: 0.7884 - recall_16: 0.8721\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8223 - precision_16: 0.7890 - recall_16: 0.8865\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8206 - precision_16: 0.7929 - recall_16: 0.8743\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.8239 - precision_16: 0.7891 - recall_16: 0.8904\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8257 - precision_16: 0.7909 - recall_16: 0.8917\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8303 - precision_16: 0.7942 - recall_16: 0.8978\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8343 - precision_16: 0.7999 - recall_16: 0.8973\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8307 - precision_16: 0.7957 - recall_16: 0.8960\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8347 - precision_16: 0.8022 - recall_16: 0.8943\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8354 - precision_16: 0.8015 - recall_16: 0.8973\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8376 - precision_16: 0.8051 - recall_16: 0.8965\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8369 - precision_16: 0.8002 - recall_16: 0.9039\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8431 - precision_16: 0.8103 - recall_16: 0.9013\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8417 - precision_16: 0.8087 - recall_16: 0.9008\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8402 - precision_16: 0.8055 - recall_16: 0.9026\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8453 - precision_16: 0.8082 - recall_16: 0.9108\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8468 - precision_16: 0.8111 - recall_16: 0.9095\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8439 - precision_16: 0.8116 - recall_16: 0.9013\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8431 - precision_16: 0.8082 - recall_16: 0.9052\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8422 - precision_16: 0.8060 - recall_16: 0.9069\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8521 - precision_16: 0.8145 - recall_16: 0.9169\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8510 - precision_16: 0.8149 - recall_16: 0.9134\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8459 - precision_16: 0.8120 - recall_16: 0.9056\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8521 - precision_16: 0.8180 - recall_16: 0.9108\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8517 - precision_16: 0.8154 - recall_16: 0.9143\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8514 - precision_16: 0.8170 - recall_16: 0.9108\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8519 - precision_16: 0.8201 - recall_16: 0.9065\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8506 - precision_16: 0.8165 - recall_16: 0.9095\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8488 - precision_16: 0.8157 - recall_16: 0.9065\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8543 - precision_16: 0.8131 - recall_16: 0.9252\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3473 - accuracy: 0.8433 - precision_16: 0.8104 - recall_16: 0.9017\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8541 - precision_16: 0.8204 - recall_16: 0.9117\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8556 - precision_16: 0.8239 - recall_16: 0.9095\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8561 - precision_16: 0.8180 - recall_16: 0.9208\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8565 - precision_16: 0.8254 - recall_16: 0.9091\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.8592 - precision_16: 0.8205 - recall_16: 0.9243\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8543 - precision_16: 0.8209 - recall_16: 0.9113\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8525 - precision_16: 0.8209 - recall_16: 0.9069\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8556 - precision_16: 0.8221 - recall_16: 0.9126\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8600 - precision_16: 0.8273 - recall_16: 0.9147\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8625 - precision_16: 0.8314 - recall_16: 0.9139\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8598 - precision_16: 0.8219 - recall_16: 0.9234\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8572 - precision_16: 0.8262 - recall_16: 0.9095\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8625 - precision_16: 0.8270 - recall_16: 0.9213\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8587 - precision_16: 0.8248 - recall_16: 0.9156\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8574 - precision_16: 0.8234 - recall_16: 0.9147\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8614 - precision_16: 0.8252 - recall_16: 0.9217\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8605 - precision_16: 0.8269 - recall_16: 0.9165\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8660 - precision_16: 0.8327 - recall_16: 0.9204\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8545 - precision_16: 0.8173 - recall_16: 0.9182\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8625 - precision_16: 0.8268 - recall_16: 0.9217\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3090 - accuracy: 0.8713 - precision_16: 0.8356 - recall_16: 0.9287\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8636 - precision_16: 0.8304 - recall_16: 0.9182\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8581 - precision_16: 0.8231 - recall_16: 0.9169\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8662 - precision_16: 0.8315 - recall_16: 0.9230\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3171 - accuracy: 0.8675 - precision_16: 0.8343 - recall_16: 0.9217\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.8706 - precision_16: 0.8354 - recall_16: 0.9274\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.8658 - precision_16: 0.8290 - recall_16: 0.9261\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8647 - precision_16: 0.8287 - recall_16: 0.9239\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8664 - precision_16: 0.8308 - recall_16: 0.9247\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8689 - precision_16: 0.8376 - recall_16: 0.9195\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8651 - precision_16: 0.8296 - recall_16: 0.9234\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8671 - precision_16: 0.8323 - recall_16: 0.9239\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8678 - precision_16: 0.8312 - recall_16: 0.9274\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8715 - precision_16: 0.8373 - recall_16: 0.9265\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 0.8700 - precision_16: 0.8344 - recall_16: 0.9274\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.8691 - precision_16: 0.8347 - recall_16: 0.9247\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.8640 - precision_16: 0.8303 - recall_16: 0.9195\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8722 - precision_16: 0.8396 - recall_16: 0.9243\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8653 - precision_16: 0.8344 - recall_16: 0.9161\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.8735 - precision_16: 0.8376 - recall_16: 0.9308\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8664 - precision_16: 0.8308 - recall_16: 0.9247\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8660 - precision_16: 0.8314 - recall_16: 0.9226\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8706 - precision_16: 0.8416 - recall_16: 0.9174\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8768 - precision_16: 0.8425 - recall_16: 0.9308\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8684 - precision_16: 0.8350 - recall_16: 0.9226\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8722 - precision_16: 0.8346 - recall_16: 0.9326\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8664 - precision_16: 0.8339 - recall_16: 0.9195\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8649 - precision_16: 0.8345 - recall_16: 0.9147\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8726 - precision_16: 0.8368 - recall_16: 0.9300\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3014 - accuracy: 0.8746 - precision_16: 0.8422 - recall_16: 0.9261\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8704 - precision_16: 0.8361 - recall_16: 0.9256\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2983 - accuracy: 0.8752 - precision_16: 0.8399 - recall_16: 0.9313\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8682 - precision_16: 0.8344 - recall_16: 0.9230\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.8739 - precision_16: 0.8420 - recall_16: 0.9247\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8735 - precision_16: 0.8432 - recall_16: 0.9217\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8678 - precision_16: 0.8351 - recall_16: 0.9208\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8748 - precision_16: 0.8374 - recall_16: 0.9343\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8719 - precision_16: 0.8403 - recall_16: 0.9226\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8571 - precision_16: 0.7994 - recall_16: 0.9364\n",
            "[CV 2/3] END ........batch_size=100, epochs=100;, score=0.857 total time=  24.5s\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 2s 4ms/step - loss: 0.6327 - accuracy: 0.6570 - precision_17: 0.6072 - recall_17: 0.8566\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7214 - precision_17: 0.6553 - recall_17: 0.9144\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7505 - precision_17: 0.6856 - recall_17: 0.9099\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7664 - precision_17: 0.7013 - recall_17: 0.9144\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7730 - precision_17: 0.7120 - recall_17: 0.9041\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7844 - precision_17: 0.7216 - recall_17: 0.9144\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7884 - precision_17: 0.7315 - recall_17: 0.9000\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8005 - precision_17: 0.7434 - recall_17: 0.9077\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8025 - precision_17: 0.7459 - recall_17: 0.9077\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8151 - precision_17: 0.7613 - recall_17: 0.9090\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8140 - precision_17: 0.7626 - recall_17: 0.9027\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8142 - precision_17: 0.7659 - recall_17: 0.8960\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8175 - precision_17: 0.7703 - recall_17: 0.8960\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8168 - precision_17: 0.7692 - recall_17: 0.8965\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8184 - precision_17: 0.7724 - recall_17: 0.8942\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8268 - precision_17: 0.7841 - recall_17: 0.8938\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8237 - precision_17: 0.7794 - recall_17: 0.8947\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8287 - precision_17: 0.7878 - recall_17: 0.8920\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8263 - precision_17: 0.7867 - recall_17: 0.8875\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8320 - precision_17: 0.7918 - recall_17: 0.8933\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8336 - precision_17: 0.7933 - recall_17: 0.8947\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8393 - precision_17: 0.7980 - recall_17: 0.9014\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8327 - precision_17: 0.7951 - recall_17: 0.8888\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8349 - precision_17: 0.7952 - recall_17: 0.8947\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8378 - precision_17: 0.7956 - recall_17: 0.9018\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8453 - precision_17: 0.8072 - recall_17: 0.9005\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8444 - precision_17: 0.8041 - recall_17: 0.9036\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3653 - accuracy: 0.8422 - precision_17: 0.8017 - recall_17: 0.9023\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8402 - precision_17: 0.8027 - recall_17: 0.8951\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8402 - precision_17: 0.8007 - recall_17: 0.8987\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8464 - precision_17: 0.8073 - recall_17: 0.9032\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8451 - precision_17: 0.8071 - recall_17: 0.9000\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8490 - precision_17: 0.8114 - recall_17: 0.9027\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8495 - precision_17: 0.8076 - recall_17: 0.9108\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8559 - precision_17: 0.8160 - recall_17: 0.9126\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8528 - precision_17: 0.8137 - recall_17: 0.9086\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8462 - precision_17: 0.8045 - recall_17: 0.9077\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8514 - precision_17: 0.8163 - recall_17: 0.9005\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8499 - precision_17: 0.8140 - recall_17: 0.9005\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8550 - precision_17: 0.8193 - recall_17: 0.9045\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8556 - precision_17: 0.8165 - recall_17: 0.9113\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8514 - precision_17: 0.8161 - recall_17: 0.9009\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8550 - precision_17: 0.8170 - recall_17: 0.9086\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8561 - precision_17: 0.8189 - recall_17: 0.9081\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8536 - precision_17: 0.8197 - recall_17: 0.9005\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8631 - precision_17: 0.8259 - recall_17: 0.9144\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.8585 - precision_17: 0.8202 - recall_17: 0.9121\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8534 - precision_17: 0.8117 - recall_17: 0.9139\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8631 - precision_17: 0.8256 - recall_17: 0.9148\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8539 - precision_17: 0.8156 - recall_17: 0.9081\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8561 - precision_17: 0.8194 - recall_17: 0.9072\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8581 - precision_17: 0.8253 - recall_17: 0.9023\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8552 - precision_17: 0.8186 - recall_17: 0.9063\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8618 - precision_17: 0.8213 - recall_17: 0.9189\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8629 - precision_17: 0.8235 - recall_17: 0.9180\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8700 - precision_17: 0.8381 - recall_17: 0.9117\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8647 - precision_17: 0.8269 - recall_17: 0.9166\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8583 - precision_17: 0.8212 - recall_17: 0.9099\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8572 - precision_17: 0.8206 - recall_17: 0.9081\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8633 - precision_17: 0.8276 - recall_17: 0.9121\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8596 - precision_17: 0.8248 - recall_17: 0.9072\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8669 - precision_17: 0.8284 - recall_17: 0.9198\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8702 - precision_17: 0.8332 - recall_17: 0.9202\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3204 - accuracy: 0.8649 - precision_17: 0.8321 - recall_17: 0.9086\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8655 - precision_17: 0.8251 - recall_17: 0.9220\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8684 - precision_17: 0.8335 - recall_17: 0.9153\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3223 - accuracy: 0.8631 - precision_17: 0.8278 - recall_17: 0.9113\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3105 - accuracy: 0.8715 - precision_17: 0.8352 - recall_17: 0.9202\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8697 - precision_17: 0.8350 - recall_17: 0.9162\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8629 - precision_17: 0.8320 - recall_17: 0.9036\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8669 - precision_17: 0.8300 - recall_17: 0.9171\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8695 - precision_17: 0.8322 - recall_17: 0.9202\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8675 - precision_17: 0.8327 - recall_17: 0.9144\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8627 - precision_17: 0.8284 - recall_17: 0.9090\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.8625 - precision_17: 0.8303 - recall_17: 0.9054\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.8633 - precision_17: 0.8286 - recall_17: 0.9104\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8750 - precision_17: 0.8421 - recall_17: 0.9180\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8647 - precision_17: 0.8277 - recall_17: 0.9153\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8680 - precision_17: 0.8342 - recall_17: 0.9130\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 0.8649 - precision_17: 0.8305 - recall_17: 0.9113\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.8669 - precision_17: 0.8322 - recall_17: 0.9135\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8750 - precision_17: 0.8382 - recall_17: 0.9242\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8717 - precision_17: 0.8383 - recall_17: 0.9157\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8748 - precision_17: 0.8418 - recall_17: 0.9180\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8715 - precision_17: 0.8405 - recall_17: 0.9117\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3009 - accuracy: 0.8746 - precision_17: 0.8378 - recall_17: 0.9238\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3095 - accuracy: 0.8697 - precision_17: 0.8377 - recall_17: 0.9117\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8726 - precision_17: 0.8383 - recall_17: 0.9180\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8706 - precision_17: 0.8325 - recall_17: 0.9225\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8715 - precision_17: 0.8391 - recall_17: 0.9139\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2999 - accuracy: 0.8737 - precision_17: 0.8356 - recall_17: 0.9251\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8757 - precision_17: 0.8417 - recall_17: 0.9202\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8695 - precision_17: 0.8382 - recall_17: 0.9104\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3044 - accuracy: 0.8757 - precision_17: 0.8390 - recall_17: 0.9247\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8794 - precision_17: 0.8456 - recall_17: 0.9234\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.8792 - precision_17: 0.8462 - recall_17: 0.9220\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8777 - precision_17: 0.8395 - recall_17: 0.9287\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.8768 - precision_17: 0.8409 - recall_17: 0.9242\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8772 - precision_17: 0.8433 - recall_17: 0.9216\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8741 - precision_17: 0.8379 - recall_17: 0.9225\n",
            "23/23 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8620 - precision_17: 0.8191 - recall_17: 0.9350\n",
            "[CV 3/3] END ........batch_size=100, epochs=100;, score=0.862 total time=  43.7s\n",
            "Epoch 1/100\n",
            "69/69 [==============================] - 3s 4ms/step - loss: 0.6229 - accuracy: 0.6345 - precision_18: 0.6355 - recall_18: 0.6215\n",
            "Epoch 2/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7311 - precision_18: 0.7479 - recall_18: 0.6927\n",
            "Epoch 3/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7575 - precision_18: 0.7588 - recall_18: 0.7512\n",
            "Epoch 4/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7728 - precision_18: 0.7659 - recall_18: 0.7822\n",
            "Epoch 5/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7860 - precision_18: 0.7703 - recall_18: 0.8118\n",
            "Epoch 6/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7902 - precision_18: 0.7760 - recall_18: 0.8126\n",
            "Epoch 7/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7978 - precision_18: 0.7754 - recall_18: 0.8354\n",
            "Epoch 8/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7957 - precision_18: 0.7687 - recall_18: 0.8428\n",
            "Epoch 9/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7990 - precision_18: 0.7705 - recall_18: 0.8484\n",
            "Epoch 10/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.8066 - precision_18: 0.7784 - recall_18: 0.8543\n",
            "Epoch 11/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8076 - precision_18: 0.7803 - recall_18: 0.8534\n",
            "Epoch 12/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8085 - precision_18: 0.7801 - recall_18: 0.8564\n",
            "Epoch 13/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.8060 - precision_18: 0.7782 - recall_18: 0.8531\n",
            "Epoch 14/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.8079 - precision_18: 0.7747 - recall_18: 0.8655\n",
            "Epoch 15/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8116 - precision_18: 0.7810 - recall_18: 0.8632\n",
            "Epoch 16/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8144 - precision_18: 0.7861 - recall_18: 0.8611\n",
            "Epoch 17/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8145 - precision_18: 0.7861 - recall_18: 0.8614\n",
            "Epoch 18/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8181 - precision_18: 0.7892 - recall_18: 0.8652\n",
            "Epoch 19/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8201 - precision_18: 0.7919 - recall_18: 0.8658\n",
            "Epoch 20/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8193 - precision_18: 0.7908 - recall_18: 0.8655\n",
            "Epoch 21/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8179 - precision_18: 0.7923 - recall_18: 0.8590\n",
            "Epoch 22/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8145 - precision_18: 0.7894 - recall_18: 0.8552\n",
            "Epoch 23/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8195 - precision_18: 0.7933 - recall_18: 0.8617\n",
            "Epoch 24/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8207 - precision_18: 0.7955 - recall_18: 0.8608\n",
            "Epoch 25/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8210 - precision_18: 0.7941 - recall_18: 0.8641\n",
            "Epoch 26/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8215 - precision_18: 0.7983 - recall_18: 0.8576\n",
            "Epoch 27/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8259 - precision_18: 0.8025 - recall_18: 0.8620\n",
            "Epoch 28/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8295 - precision_18: 0.8063 - recall_18: 0.8650\n",
            "Epoch 29/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8247 - precision_18: 0.7997 - recall_18: 0.8638\n",
            "Epoch 30/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8235 - precision_18: 0.8014 - recall_18: 0.8576\n",
            "Epoch 31/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8326 - precision_18: 0.8058 - recall_18: 0.8741\n",
            "Epoch 32/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8267 - precision_18: 0.7963 - recall_18: 0.8756\n",
            "Epoch 33/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8282 - precision_18: 0.8005 - recall_18: 0.8717\n",
            "Epoch 34/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8301 - precision_18: 0.8014 - recall_18: 0.8753\n",
            "Epoch 35/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8372 - precision_18: 0.8041 - recall_18: 0.8892\n",
            "Epoch 36/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8353 - precision_18: 0.7989 - recall_18: 0.8936\n",
            "Epoch 37/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8397 - precision_18: 0.8063 - recall_18: 0.8918\n",
            "Epoch 38/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8335 - precision_18: 0.8015 - recall_18: 0.8842\n",
            "Epoch 39/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8363 - precision_18: 0.7987 - recall_18: 0.8969\n",
            "Epoch 40/100\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8438 - precision_18: 0.8076 - recall_18: 0.9004\n",
            "Epoch 41/100\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8407 - precision_18: 0.8057 - recall_18: 0.8957\n",
            "Epoch 42/100\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8397 - precision_18: 0.8052 - recall_18: 0.8939\n",
            "Epoch 43/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8454 - precision_18: 0.8170 - recall_18: 0.8880\n",
            "Epoch 44/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8488 - precision_18: 0.8166 - recall_18: 0.8975\n",
            "Epoch 45/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8495 - precision_18: 0.8169 - recall_18: 0.8989\n",
            "Epoch 46/100\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8354 - precision_18: 0.7998 - recall_18: 0.8924\n",
            "Epoch 47/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8439 - precision_18: 0.8049 - recall_18: 0.9057\n",
            "Epoch 48/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8357 - precision_18: 0.8036 - recall_18: 0.8862\n",
            "Epoch 49/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8347 - precision_18: 0.7983 - recall_18: 0.8933\n",
            "Epoch 50/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8457 - precision_18: 0.8094 - recall_18: 0.9022\n",
            "Epoch 51/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8504 - precision_18: 0.8156 - recall_18: 0.9034\n",
            "Epoch 52/100\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8426 - precision_18: 0.8082 - recall_18: 0.8963\n",
            "Epoch 53/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8483 - precision_18: 0.8124 - recall_18: 0.9037\n",
            "Epoch 54/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.8475 - precision_18: 0.8121 - recall_18: 0.9019\n",
            "Epoch 55/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8544 - precision_18: 0.8217 - recall_18: 0.9031\n",
            "Epoch 56/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8203 - precision_18: 0.7852 - recall_18: 0.8791\n",
            "Epoch 57/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8382 - precision_18: 0.7969 - recall_18: 0.9054\n",
            "Epoch 58/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8434 - precision_18: 0.8048 - recall_18: 0.9043\n",
            "Epoch 59/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8366 - precision_18: 0.8024 - recall_18: 0.8907\n",
            "Epoch 60/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8469 - precision_18: 0.8070 - recall_18: 0.9096\n",
            "Epoch 61/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8523 - precision_18: 0.8133 - recall_18: 0.9125\n",
            "Epoch 62/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8406 - precision_18: 0.8048 - recall_18: 0.8969\n",
            "Epoch 63/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3572 - accuracy: 0.8481 - precision_18: 0.8122 - recall_18: 0.9034\n",
            "Epoch 64/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3605 - accuracy: 0.8456 - precision_18: 0.8085 - recall_18: 0.9034\n",
            "Epoch 65/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8414 - precision_18: 0.8064 - recall_18: 0.8963\n",
            "Epoch 66/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8520 - precision_18: 0.8138 - recall_18: 0.9108\n",
            "Epoch 67/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8519 - precision_18: 0.8141 - recall_18: 0.9099\n",
            "Epoch 68/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8492 - precision_18: 0.8197 - recall_18: 0.8933\n",
            "Epoch 69/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8563 - precision_18: 0.8191 - recall_18: 0.9125\n",
            "Epoch 70/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8551 - precision_18: 0.8208 - recall_18: 0.9066\n",
            "Epoch 71/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8555 - precision_18: 0.8143 - recall_18: 0.9190\n",
            "Epoch 72/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8561 - precision_18: 0.8192 - recall_18: 0.9119\n",
            "Epoch 73/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8569 - precision_18: 0.8198 - recall_18: 0.9128\n",
            "Epoch 74/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8578 - precision_18: 0.8216 - recall_18: 0.9119\n",
            "Epoch 75/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8481 - precision_18: 0.8102 - recall_18: 0.9069\n",
            "Epoch 76/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8573 - precision_18: 0.8174 - recall_18: 0.9181\n",
            "Epoch 77/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8594 - precision_18: 0.8244 - recall_18: 0.9113\n",
            "Epoch 78/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8605 - precision_18: 0.8227 - recall_18: 0.9173\n",
            "Epoch 79/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8547 - precision_18: 0.8244 - recall_18: 0.8992\n",
            "Epoch 80/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8491 - precision_18: 0.8200 - recall_18: 0.8924\n",
            "Epoch 81/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8513 - precision_18: 0.8113 - recall_18: 0.9134\n",
            "Epoch 82/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8582 - precision_18: 0.8247 - recall_18: 0.9078\n",
            "Epoch 83/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8607 - precision_18: 0.8217 - recall_18: 0.9193\n",
            "Epoch 84/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8626 - precision_18: 0.8293 - recall_18: 0.9113\n",
            "Epoch 85/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8601 - precision_18: 0.8207 - recall_18: 0.9196\n",
            "Epoch 86/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8611 - precision_18: 0.8253 - recall_18: 0.9143\n",
            "Epoch 87/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8667 - precision_18: 0.8328 - recall_18: 0.9158\n",
            "Epoch 88/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8611 - precision_18: 0.8286 - recall_18: 0.9087\n",
            "Epoch 89/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8623 - precision_18: 0.8269 - recall_18: 0.9146\n",
            "Epoch 90/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8697 - precision_18: 0.8334 - recall_18: 0.9223\n",
            "Epoch 91/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8611 - precision_18: 0.8277 - recall_18: 0.9102\n",
            "Epoch 92/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.8647 - precision_18: 0.8322 - recall_18: 0.9116\n",
            "Epoch 93/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8695 - precision_18: 0.8340 - recall_18: 0.9208\n",
            "Epoch 94/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8694 - precision_18: 0.8329 - recall_18: 0.9223\n",
            "Epoch 95/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8567 - precision_18: 0.8125 - recall_18: 0.9255\n",
            "Epoch 96/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8660 - precision_18: 0.8277 - recall_18: 0.9226\n",
            "Epoch 97/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8686 - precision_18: 0.8334 - recall_18: 0.9196\n",
            "Epoch 98/100\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8639 - precision_18: 0.8302 - recall_18: 0.9131\n",
            "Epoch 99/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8701 - precision_18: 0.8314 - recall_18: 0.9267\n",
            "Epoch 100/100\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8683 - precision_18: 0.8348 - recall_18: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fom1lr4pMku4",
        "outputId": "d680d78b-75e1-4c03-8ab9-3a8bbe5138fe"
      },
      "source": [
        "best_parameters = grid.best_params_\n",
        "print(best_parameters)\n",
        "best_score = grid.best_score_\n",
        "print(best_score)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 100, 'epochs': 100}\n",
            "0.8623063365618387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqKDaC5aUQtc"
      },
      "source": [
        "Fitting to the model on the best hyperparameters we obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiauYJNtQXLB",
        "outputId": "1871217b-b485-4f21-aa82-f022bcb6c9c9"
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 100, batch_size=50)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "137/137 [==============================] - 3s 7ms/step - loss: 0.6591 - accuracy: 0.6508 - precision_19: 0.7360 - recall_19: 0.4645 - val_loss: 0.6447 - val_accuracy: 0.6469 - val_precision_19: 0.7492 - val_recall_19: 0.4550\n",
            "Epoch 2/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.5869 - accuracy: 0.7080 - precision_19: 0.7651 - recall_19: 0.5957 - val_loss: 0.5926 - val_accuracy: 0.7110 - val_precision_19: 0.7255 - val_recall_19: 0.6906\n",
            "Epoch 3/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.5315 - accuracy: 0.7559 - precision_19: 0.7752 - recall_19: 0.7172 - val_loss: 0.5363 - val_accuracy: 0.7477 - val_precision_19: 0.7066 - val_recall_19: 0.8578\n",
            "Epoch 4/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4889 - accuracy: 0.7783 - precision_19: 0.7593 - recall_19: 0.8112 - val_loss: 0.4705 - val_accuracy: 0.7912 - val_precision_19: 0.7449 - val_recall_19: 0.8937\n",
            "Epoch 5/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4595 - accuracy: 0.7904 - precision_19: 0.7551 - recall_19: 0.8564 - val_loss: 0.4517 - val_accuracy: 0.7912 - val_precision_19: 0.7291 - val_recall_19: 0.9350\n",
            "Epoch 6/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4427 - accuracy: 0.7974 - precision_19: 0.7583 - recall_19: 0.8697 - val_loss: 0.4567 - val_accuracy: 0.7847 - val_precision_19: 0.7266 - val_recall_19: 0.9215\n",
            "Epoch 7/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4377 - accuracy: 0.8013 - precision_19: 0.7577 - recall_19: 0.8827 - val_loss: 0.4221 - val_accuracy: 0.8029 - val_precision_19: 0.7701 - val_recall_19: 0.8707\n",
            "Epoch 8/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4249 - accuracy: 0.8028 - precision_19: 0.7681 - recall_19: 0.8644 - val_loss: 0.4132 - val_accuracy: 0.8060 - val_precision_19: 0.7729 - val_recall_19: 0.8734\n",
            "Epoch 9/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4169 - accuracy: 0.8087 - precision_19: 0.7724 - recall_19: 0.8723 - val_loss: 0.4030 - val_accuracy: 0.8094 - val_precision_19: 0.7698 - val_recall_19: 0.8896\n",
            "Epoch 10/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4194 - accuracy: 0.8057 - precision_19: 0.7668 - recall_19: 0.8756 - val_loss: 0.4010 - val_accuracy: 0.8097 - val_precision_19: 0.7547 - val_recall_19: 0.9248\n",
            "Epoch 11/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4153 - accuracy: 0.8081 - precision_19: 0.7718 - recall_19: 0.8717 - val_loss: 0.3984 - val_accuracy: 0.8162 - val_precision_19: 0.7836 - val_recall_19: 0.8802\n",
            "Epoch 12/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.8116 - precision_19: 0.7740 - recall_19: 0.8774 - val_loss: 0.3875 - val_accuracy: 0.8269 - val_precision_19: 0.7893 - val_recall_19: 0.8978\n",
            "Epoch 13/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.4001 - accuracy: 0.8154 - precision_19: 0.7793 - recall_19: 0.8774 - val_loss: 0.3868 - val_accuracy: 0.8269 - val_precision_19: 0.7872 - val_recall_19: 0.9018\n",
            "Epoch 14/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3947 - accuracy: 0.8185 - precision_19: 0.7782 - recall_19: 0.8883 - val_loss: 0.3780 - val_accuracy: 0.8293 - val_precision_19: 0.7808 - val_recall_19: 0.9215\n",
            "Epoch 15/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3950 - accuracy: 0.8172 - precision_19: 0.7773 - recall_19: 0.8862 - val_loss: 0.3850 - val_accuracy: 0.8262 - val_precision_19: 0.7685 - val_recall_19: 0.9397\n",
            "Epoch 16/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3882 - accuracy: 0.8160 - precision_19: 0.7775 - recall_19: 0.8827 - val_loss: 0.3735 - val_accuracy: 0.8279 - val_precision_19: 0.7876 - val_recall_19: 0.9039\n",
            "Epoch 17/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8198 - precision_19: 0.7800 - recall_19: 0.8883 - val_loss: 0.3693 - val_accuracy: 0.8265 - val_precision_19: 0.7808 - val_recall_19: 0.9140\n",
            "Epoch 18/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3837 - accuracy: 0.8235 - precision_19: 0.7817 - recall_19: 0.8951 - val_loss: 0.3673 - val_accuracy: 0.8245 - val_precision_19: 0.7817 - val_recall_19: 0.9066\n",
            "Epoch 19/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3846 - accuracy: 0.8247 - precision_19: 0.7849 - recall_19: 0.8918 - val_loss: 0.3638 - val_accuracy: 0.8313 - val_precision_19: 0.7819 - val_recall_19: 0.9248\n",
            "Epoch 20/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3743 - accuracy: 0.8284 - precision_19: 0.7872 - recall_19: 0.8975 - val_loss: 0.3789 - val_accuracy: 0.8169 - val_precision_19: 0.8036 - val_recall_19: 0.8450\n",
            "Epoch 21/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3785 - accuracy: 0.8275 - precision_19: 0.7899 - recall_19: 0.8898 - val_loss: 0.3609 - val_accuracy: 0.8289 - val_precision_19: 0.7907 - val_recall_19: 0.9005\n",
            "Epoch 22/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8282 - precision_19: 0.7901 - recall_19: 0.8913 - val_loss: 0.3624 - val_accuracy: 0.8293 - val_precision_19: 0.7838 - val_recall_19: 0.9154\n",
            "Epoch 23/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8248 - precision_19: 0.7807 - recall_19: 0.9007 - val_loss: 0.3670 - val_accuracy: 0.8334 - val_precision_19: 0.7913 - val_recall_19: 0.9113\n",
            "Epoch 24/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3726 - accuracy: 0.8325 - precision_19: 0.7892 - recall_19: 0.9048 - val_loss: 0.3554 - val_accuracy: 0.8444 - val_precision_19: 0.7976 - val_recall_19: 0.9282\n",
            "Epoch 25/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3700 - accuracy: 0.8291 - precision_19: 0.7876 - recall_19: 0.8986 - val_loss: 0.3500 - val_accuracy: 0.8375 - val_precision_19: 0.8012 - val_recall_19: 0.9032\n",
            "Epoch 26/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3682 - accuracy: 0.8276 - precision_19: 0.7862 - recall_19: 0.8975 - val_loss: 0.3679 - val_accuracy: 0.8327 - val_precision_19: 0.7701 - val_recall_19: 0.9546\n",
            "Epoch 27/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3748 - accuracy: 0.8269 - precision_19: 0.7872 - recall_19: 0.8933 - val_loss: 0.3629 - val_accuracy: 0.8337 - val_precision_19: 0.7815 - val_recall_19: 0.9323\n",
            "Epoch 28/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8181 - precision_19: 0.7860 - recall_19: 0.8715 - val_loss: 0.3649 - val_accuracy: 0.8262 - val_precision_19: 0.7787 - val_recall_19: 0.9174\n",
            "Epoch 29/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3725 - accuracy: 0.8276 - precision_19: 0.7904 - recall_19: 0.8892 - val_loss: 0.3553 - val_accuracy: 0.8348 - val_precision_19: 0.7877 - val_recall_19: 0.9221\n",
            "Epoch 30/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3650 - accuracy: 0.8341 - precision_19: 0.7934 - recall_19: 0.9010 - val_loss: 0.3435 - val_accuracy: 0.8488 - val_precision_19: 0.8106 - val_recall_19: 0.9154\n",
            "Epoch 31/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3646 - accuracy: 0.8320 - precision_19: 0.7925 - recall_19: 0.8972 - val_loss: 0.3592 - val_accuracy: 0.8330 - val_precision_19: 0.7720 - val_recall_19: 0.9513\n",
            "Epoch 32/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3876 - accuracy: 0.8184 - precision_19: 0.7813 - recall_19: 0.8815 - val_loss: 0.3644 - val_accuracy: 0.8358 - val_precision_19: 0.7874 - val_recall_19: 0.9255\n",
            "Epoch 33/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3638 - accuracy: 0.8359 - precision_19: 0.7970 - recall_19: 0.8989 - val_loss: 0.3556 - val_accuracy: 0.8392 - val_precision_19: 0.8029 - val_recall_19: 0.9045\n",
            "Epoch 34/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3683 - accuracy: 0.8339 - precision_19: 0.7970 - recall_19: 0.8936 - val_loss: 0.3443 - val_accuracy: 0.8406 - val_precision_19: 0.8159 - val_recall_19: 0.8849\n",
            "Epoch 35/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3624 - accuracy: 0.8376 - precision_19: 0.7979 - recall_19: 0.9019 - val_loss: 0.3493 - val_accuracy: 0.8402 - val_precision_19: 0.8011 - val_recall_19: 0.9106\n",
            "Epoch 36/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8414 - precision_19: 0.8021 - recall_19: 0.9043 - val_loss: 0.3466 - val_accuracy: 0.8471 - val_precision_19: 0.7951 - val_recall_19: 0.9404\n",
            "Epoch 37/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3617 - accuracy: 0.8356 - precision_19: 0.7967 - recall_19: 0.8986 - val_loss: 0.3365 - val_accuracy: 0.8502 - val_precision_19: 0.7985 - val_recall_19: 0.9418\n",
            "Epoch 38/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3508 - accuracy: 0.8442 - precision_19: 0.8060 - recall_19: 0.9046 - val_loss: 0.3310 - val_accuracy: 0.8516 - val_precision_19: 0.8063 - val_recall_19: 0.9303\n",
            "Epoch 39/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3473 - accuracy: 0.8422 - precision_19: 0.8038 - recall_19: 0.9031 - val_loss: 0.3386 - val_accuracy: 0.8519 - val_precision_19: 0.8108 - val_recall_19: 0.9228\n",
            "Epoch 40/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3504 - accuracy: 0.8453 - precision_19: 0.8053 - recall_19: 0.9084 - val_loss: 0.3323 - val_accuracy: 0.8543 - val_precision_19: 0.8044 - val_recall_19: 0.9411\n",
            "Epoch 41/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3472 - accuracy: 0.8472 - precision_19: 0.8089 - recall_19: 0.9069 - val_loss: 0.3448 - val_accuracy: 0.8430 - val_precision_19: 0.7890 - val_recall_19: 0.9418\n",
            "Epoch 42/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3482 - accuracy: 0.8439 - precision_19: 0.8035 - recall_19: 0.9084 - val_loss: 0.3410 - val_accuracy: 0.8492 - val_precision_19: 0.8006 - val_recall_19: 0.9350\n",
            "Epoch 43/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3526 - accuracy: 0.8435 - precision_19: 0.8020 - recall_19: 0.9099 - val_loss: 0.3393 - val_accuracy: 0.8526 - val_precision_19: 0.8074 - val_recall_19: 0.9309\n",
            "Epoch 44/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3392 - accuracy: 0.8513 - precision_19: 0.8113 - recall_19: 0.9134 - val_loss: 0.3292 - val_accuracy: 0.8598 - val_precision_19: 0.8268 - val_recall_19: 0.9147\n",
            "Epoch 45/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3441 - accuracy: 0.8469 - precision_19: 0.8100 - recall_19: 0.9043 - val_loss: 0.3425 - val_accuracy: 0.8481 - val_precision_19: 0.7850 - val_recall_19: 0.9641\n",
            "Epoch 46/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3455 - accuracy: 0.8482 - precision_19: 0.8089 - recall_19: 0.9096 - val_loss: 0.3341 - val_accuracy: 0.8598 - val_precision_19: 0.8232 - val_recall_19: 0.9208\n",
            "Epoch 47/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.8451 - precision_19: 0.8095 - recall_19: 0.9004 - val_loss: 0.3314 - val_accuracy: 0.8488 - val_precision_19: 0.7884 - val_recall_19: 0.9587\n",
            "Epoch 48/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3392 - accuracy: 0.8533 - precision_19: 0.8161 - recall_19: 0.9102 - val_loss: 0.3265 - val_accuracy: 0.8543 - val_precision_19: 0.8176 - val_recall_19: 0.9167\n",
            "Epoch 49/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3505 - accuracy: 0.8429 - precision_19: 0.8073 - recall_19: 0.8986 - val_loss: 0.3225 - val_accuracy: 0.8618 - val_precision_19: 0.8041 - val_recall_19: 0.9614\n",
            "Epoch 50/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3403 - accuracy: 0.8507 - precision_19: 0.8111 - recall_19: 0.9122 - val_loss: 0.3288 - val_accuracy: 0.8553 - val_precision_19: 0.8013 - val_recall_19: 0.9499\n",
            "Epoch 51/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8529 - precision_19: 0.8151 - recall_19: 0.9108 - val_loss: 0.3314 - val_accuracy: 0.8591 - val_precision_19: 0.7964 - val_recall_19: 0.9695\n",
            "Epoch 52/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8532 - precision_19: 0.8167 - recall_19: 0.9087 - val_loss: 0.3250 - val_accuracy: 0.8594 - val_precision_19: 0.8122 - val_recall_19: 0.9397\n",
            "Epoch 53/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.8445 - precision_19: 0.8131 - recall_19: 0.8924 - val_loss: 0.3268 - val_accuracy: 0.8529 - val_precision_19: 0.8104 - val_recall_19: 0.9262\n",
            "Epoch 54/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8523 - precision_19: 0.8164 - recall_19: 0.9069 - val_loss: 0.3305 - val_accuracy: 0.8564 - val_precision_19: 0.8179 - val_recall_19: 0.9215\n",
            "Epoch 55/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3421 - accuracy: 0.8492 - precision_19: 0.8139 - recall_19: 0.9034 - val_loss: 0.3322 - val_accuracy: 0.8526 - val_precision_19: 0.8035 - val_recall_19: 0.9384\n",
            "Epoch 56/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.8519 - precision_19: 0.8140 - recall_19: 0.9102 - val_loss: 0.3417 - val_accuracy: 0.8468 - val_precision_19: 0.8163 - val_recall_19: 0.8998\n",
            "Epoch 57/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3339 - accuracy: 0.8583 - precision_19: 0.8203 - recall_19: 0.9158 - val_loss: 0.3187 - val_accuracy: 0.8670 - val_precision_19: 0.8266 - val_recall_19: 0.9330\n",
            "Epoch 58/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3407 - accuracy: 0.8553 - precision_19: 0.8189 - recall_19: 0.9102 - val_loss: 0.3262 - val_accuracy: 0.8605 - val_precision_19: 0.8050 - val_recall_19: 0.9560\n",
            "Epoch 59/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3361 - accuracy: 0.8523 - precision_19: 0.8176 - recall_19: 0.9048 - val_loss: 0.3264 - val_accuracy: 0.8564 - val_precision_19: 0.8233 - val_recall_19: 0.9120\n",
            "Epoch 60/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3297 - accuracy: 0.8592 - precision_19: 0.8229 - recall_19: 0.9134 - val_loss: 0.3305 - val_accuracy: 0.8546 - val_precision_19: 0.8042 - val_recall_19: 0.9425\n",
            "Epoch 61/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8476 - precision_19: 0.8114 - recall_19: 0.9037 - val_loss: 0.3265 - val_accuracy: 0.8584 - val_precision_19: 0.8104 - val_recall_19: 0.9404\n",
            "Epoch 62/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3389 - accuracy: 0.8513 - precision_19: 0.8148 - recall_19: 0.9072 - val_loss: 0.3185 - val_accuracy: 0.8660 - val_precision_19: 0.8213 - val_recall_19: 0.9397\n",
            "Epoch 63/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8578 - precision_19: 0.8225 - recall_19: 0.9105 - val_loss: 0.3162 - val_accuracy: 0.8649 - val_precision_19: 0.8412 - val_recall_19: 0.9039\n",
            "Epoch 64/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8495 - precision_19: 0.8164 - recall_19: 0.8998 - val_loss: 0.3206 - val_accuracy: 0.8536 - val_precision_19: 0.8024 - val_recall_19: 0.9431\n",
            "Epoch 65/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3233 - accuracy: 0.8561 - precision_19: 0.8213 - recall_19: 0.9084 - val_loss: 0.3131 - val_accuracy: 0.8622 - val_precision_19: 0.8141 - val_recall_19: 0.9431\n",
            "Epoch 66/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.8586 - precision_19: 0.8229 - recall_19: 0.9119 - val_loss: 0.3111 - val_accuracy: 0.8684 - val_precision_19: 0.8367 - val_recall_19: 0.9194\n",
            "Epoch 67/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8525 - precision_19: 0.8178 - recall_19: 0.9048 - val_loss: 0.3332 - val_accuracy: 0.8581 - val_precision_19: 0.7978 - val_recall_19: 0.9641\n",
            "Epoch 68/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3395 - accuracy: 0.8503 - precision_19: 0.8154 - recall_19: 0.9034 - val_loss: 0.3260 - val_accuracy: 0.8608 - val_precision_19: 0.8275 - val_recall_19: 0.9160\n",
            "Epoch 69/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3277 - accuracy: 0.8591 - precision_19: 0.8266 - recall_19: 0.9069 - val_loss: 0.3265 - val_accuracy: 0.8605 - val_precision_19: 0.8319 - val_recall_19: 0.9079\n",
            "Epoch 70/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8558 - precision_19: 0.8164 - recall_19: 0.9161 - val_loss: 0.3226 - val_accuracy: 0.8598 - val_precision_19: 0.8116 - val_recall_19: 0.9418\n",
            "Epoch 71/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3158 - accuracy: 0.8607 - precision_19: 0.8248 - recall_19: 0.9140 - val_loss: 0.3129 - val_accuracy: 0.8646 - val_precision_19: 0.8311 - val_recall_19: 0.9194\n",
            "Epoch 72/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3267 - accuracy: 0.8544 - precision_19: 0.8212 - recall_19: 0.9040 - val_loss: 0.3193 - val_accuracy: 0.8577 - val_precision_19: 0.8222 - val_recall_19: 0.9174\n",
            "Epoch 73/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3429 - accuracy: 0.8479 - precision_19: 0.8162 - recall_19: 0.8960 - val_loss: 0.3266 - val_accuracy: 0.8608 - val_precision_19: 0.8328 - val_recall_19: 0.9072\n",
            "Epoch 74/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8563 - precision_19: 0.8208 - recall_19: 0.9096 - val_loss: 0.3172 - val_accuracy: 0.8680 - val_precision_19: 0.8301 - val_recall_19: 0.9296\n",
            "Epoch 75/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3200 - accuracy: 0.8629 - precision_19: 0.8248 - recall_19: 0.9196 - val_loss: 0.3164 - val_accuracy: 0.8618 - val_precision_19: 0.8243 - val_recall_19: 0.9242\n",
            "Epoch 76/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.8625 - precision_19: 0.8299 - recall_19: 0.9099 - val_loss: 0.3026 - val_accuracy: 0.8690 - val_precision_19: 0.8292 - val_recall_19: 0.9336\n",
            "Epoch 77/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3182 - accuracy: 0.8591 - precision_19: 0.8262 - recall_19: 0.9075 - val_loss: 0.3169 - val_accuracy: 0.8636 - val_precision_19: 0.8128 - val_recall_19: 0.9492\n",
            "Epoch 78/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.8655 - precision_19: 0.8311 - recall_19: 0.9158 - val_loss: 0.3018 - val_accuracy: 0.8749 - val_precision_19: 0.8278 - val_recall_19: 0.9506\n",
            "Epoch 79/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3175 - accuracy: 0.8622 - precision_19: 0.8288 - recall_19: 0.9111 - val_loss: 0.3172 - val_accuracy: 0.8622 - val_precision_19: 0.8201 - val_recall_19: 0.9323\n",
            "Epoch 80/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3167 - accuracy: 0.8614 - precision_19: 0.8278 - recall_19: 0.9108 - val_loss: 0.3137 - val_accuracy: 0.8663 - val_precision_19: 0.8477 - val_recall_19: 0.8971\n",
            "Epoch 81/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8570 - precision_19: 0.8241 - recall_19: 0.9057 - val_loss: 0.3163 - val_accuracy: 0.8666 - val_precision_19: 0.8094 - val_recall_19: 0.9634\n",
            "Epoch 82/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3277 - accuracy: 0.8570 - precision_19: 0.8221 - recall_19: 0.9093 - val_loss: 0.3149 - val_accuracy: 0.8656 - val_precision_19: 0.8116 - val_recall_19: 0.9567\n",
            "Epoch 83/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3110 - accuracy: 0.8655 - precision_19: 0.8288 - recall_19: 0.9196 - val_loss: 0.3014 - val_accuracy: 0.8732 - val_precision_19: 0.8419 - val_recall_19: 0.9228\n",
            "Epoch 84/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3201 - accuracy: 0.8636 - precision_19: 0.8282 - recall_19: 0.9158 - val_loss: 0.3060 - val_accuracy: 0.8708 - val_precision_19: 0.8262 - val_recall_19: 0.9431\n",
            "Epoch 85/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3285 - accuracy: 0.8535 - precision_19: 0.8213 - recall_19: 0.9016 - val_loss: 0.3028 - val_accuracy: 0.8714 - val_precision_19: 0.8280 - val_recall_19: 0.9418\n",
            "Epoch 86/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3096 - accuracy: 0.8652 - precision_19: 0.8301 - recall_19: 0.9167 - val_loss: 0.3017 - val_accuracy: 0.8810 - val_precision_19: 0.8585 - val_recall_19: 0.9160\n",
            "Epoch 87/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3129 - accuracy: 0.8630 - precision_19: 0.8290 - recall_19: 0.9128 - val_loss: 0.3050 - val_accuracy: 0.8687 - val_precision_19: 0.8356 - val_recall_19: 0.9221\n",
            "Epoch 88/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.8625 - precision_19: 0.8322 - recall_19: 0.9060 - val_loss: 0.3053 - val_accuracy: 0.8694 - val_precision_19: 0.8197 - val_recall_19: 0.9513\n",
            "Epoch 89/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3044 - accuracy: 0.8692 - precision_19: 0.8315 - recall_19: 0.9243 - val_loss: 0.3042 - val_accuracy: 0.8735 - val_precision_19: 0.8349 - val_recall_19: 0.9350\n",
            "Epoch 90/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3143 - accuracy: 0.8626 - precision_19: 0.8318 - recall_19: 0.9072 - val_loss: 0.2994 - val_accuracy: 0.8714 - val_precision_19: 0.8315 - val_recall_19: 0.9357\n",
            "Epoch 91/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3053 - accuracy: 0.8691 - precision_19: 0.8383 - recall_19: 0.9128 - val_loss: 0.3133 - val_accuracy: 0.8615 - val_precision_19: 0.8107 - val_recall_19: 0.9479\n",
            "Epoch 92/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3767 - accuracy: 0.8322 - precision_19: 0.8012 - recall_19: 0.8812 - val_loss: 0.3542 - val_accuracy: 0.8461 - val_precision_19: 0.7834 - val_recall_19: 0.9621\n",
            "Epoch 93/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3430 - accuracy: 0.8542 - precision_19: 0.8156 - recall_19: 0.9134 - val_loss: 0.3188 - val_accuracy: 0.8632 - val_precision_19: 0.8141 - val_recall_19: 0.9458\n",
            "Epoch 94/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8576 - precision_19: 0.8216 - recall_19: 0.9116 - val_loss: 0.3194 - val_accuracy: 0.8687 - val_precision_19: 0.8158 - val_recall_19: 0.9567\n",
            "Epoch 95/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.8638 - precision_19: 0.8277 - recall_19: 0.9170 - val_loss: 0.3065 - val_accuracy: 0.8711 - val_precision_19: 0.8252 - val_recall_19: 0.9458\n",
            "Epoch 96/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3129 - accuracy: 0.8679 - precision_19: 0.8288 - recall_19: 0.9255 - val_loss: 0.3092 - val_accuracy: 0.8670 - val_precision_19: 0.8231 - val_recall_19: 0.9391\n",
            "Epoch 97/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3167 - accuracy: 0.8641 - precision_19: 0.8274 - recall_19: 0.9181 - val_loss: 0.2968 - val_accuracy: 0.8762 - val_precision_19: 0.8428 - val_recall_19: 0.9289\n",
            "Epoch 98/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.8594 - precision_19: 0.8218 - recall_19: 0.9158 - val_loss: 0.3044 - val_accuracy: 0.8735 - val_precision_19: 0.8374 - val_recall_19: 0.9309\n",
            "Epoch 99/100\n",
            "137/137 [==============================] - 1s 5ms/step - loss: 0.3118 - accuracy: 0.8648 - precision_19: 0.8306 - recall_19: 0.9146 - val_loss: 0.3042 - val_accuracy: 0.8690 - val_precision_19: 0.8234 - val_recall_19: 0.9438\n",
            "Epoch 100/100\n",
            "137/137 [==============================] - 1s 4ms/step - loss: 0.3163 - accuracy: 0.8627 - precision_19: 0.8230 - recall_19: 0.9223 - val_loss: 0.3030 - val_accuracy: 0.8708 - val_precision_19: 0.8213 - val_recall_19: 0.9519\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbd5edef10>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wih9ltzbVH5F"
      },
      "source": [
        "We achieved 87% accuracy on the test set which is a great result."
      ]
    }
  ]
}